<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NYSDY</title>
  
  <subtitle>NYSDY</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://nysdy.com/"/>
  <updated>2020-08-21T08:50:07.444Z</updated>
  <id>http://nysdy.com/</id>
  
  <author>
    <name>NYSDY</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ubantu系统安装pytorch GPU版本</title>
    <link href="http://nysdy.com/post/ubantu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85pytorch-GPU%E7%89%88%E6%9C%AC/"/>
    <id>http://nysdy.com/post/ubantu系统安装pytorch-GPU版本/</id>
    <published>2020-08-21T07:50:16.000Z</published>
    <updated>2020-08-21T08:50:07.444Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;0-准备工作&quot;&gt;&lt;a href=&quot;#0-准备工作&quot; class=&quot;headerlink&quot; title=&quot;0 准备工作&quot;&gt;&lt;/a&gt;&lt;strong&gt;0
        
      
    
    </summary>
    
      <category term="技术" scheme="http://nysdy.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="python" scheme="http://nysdy.com/tags/python/"/>
    
      <category term="pytorch" scheme="http://nysdy.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Diachronic Embedding for Temporal Knowledge Graph Completion</title>
    <link href="http://nysdy.com/post/null/"/>
    <id>http://nysdy.com/post/null/</id>
    <published>2020-07-02T11:09:49.000Z</published>
    <updated>2020-07-02T11:21:43.714Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1907.03143.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="KG" scheme="http://nysdy.com/tags/KG/"/>
    
      <category term="temporal KG" scheme="http://nysdy.com/tags/temporal-KG/"/>
    
      <category term="2019" scheme="http://nysdy.com/tags/2019/"/>
    
  </entry>
  
  <entry>
    <title>更新博客主题</title>
    <link href="http://nysdy.com/post/Update-blog-theme/"/>
    <id>http://nysdy.com/post/Update-blog-theme/</id>
    <published>2020-03-26T06:54:40.000Z</published>
    <updated>2020-03-26T06:58:11.398Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;正好赶上最近有空，修改升级一下自己的博客，之前用的是&lt;code&gt;next&lt;/code&gt;主题，偶然间发现了&lt;code&gt;matery&lt;/code&gt;主题，感觉更加漂亮一些，就决定更换一下，顺便记录自己的一些更换操作。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://nysdy.com/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="hexo" scheme="http://nysdy.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>2016 TransG : A Generative Model for Knowledge Graph Embedding阅读笔记</title>
    <link href="http://nysdy.com/post/TransG_:_A_Generative_Model_for_Knowledge_Graph_Embedding/"/>
    <id>http://nysdy.com/post/TransG_:_A_Generative_Model_for_Knowledge_Graph_Embedding/</id>
    <published>2019-10-12T02:03:44.000Z</published>
    <updated>2019-10-25T07:43:08.240Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/P16-1219.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="2016" scheme="http://nysdy.com/tags/2016/"/>
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="ACL" scheme="http://nysdy.com/tags/ACL/"/>
    
  </entry>
  
  <entry>
    <title>2016 Knowledge Graph Completion with Adaptive Sparse Transfer Matrix阅读笔记</title>
    <link href="http://nysdy.com/post/2016_Knowledge_Graph_Completion_with_Adaptive_Sparse_Transfer_Matrix/"/>
    <id>http://nysdy.com/post/2016_Knowledge_Graph_Completion_with_Adaptive_Sparse_Transfer_Matrix/</id>
    <published>2019-09-10T01:16:53.000Z</published>
    <updated>2019-10-12T05:30:51.532Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;为解决heterogeneity和imbalance问题，作者针对同一关系链接实体对的数量和同一关系不同头尾实体数量，分别设计了不同稀疏程度的转移矩阵。存在缺点：并没有同时解决这两个问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="2016" scheme="http://nysdy.com/tags/2016/"/>
    
      <category term="AAAI" scheme="http://nysdy.com/tags/AAAI/"/>
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
  </entry>
  
  <entry>
    <title>2015 TransA An Adaptive Approach for Knowledge Graph Embeddin阅读笔记</title>
    <link href="http://nysdy.com/post/2015_TransA_An_Adaptive_Approach_for_Knowledge_Graph_Embeddin/"/>
    <id>http://nysdy.com/post/2015_TransA_An_Adaptive_Approach_for_Knowledge_Graph_Embeddin/</id>
    <published>2019-09-02T06:32:48.000Z</published>
    <updated>2020-08-21T08:39:38.311Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章具体的公式操作比较难以理解，但是对于我来说，它的每一维度加权和最后判断时也应该考虑不同维度差异和我的思路比较像。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.05490&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="TransA" scheme="http://nysdy.com/tags/TransA/"/>
    
      <category term="2015" scheme="http://nysdy.com/tags/2015/"/>
    
      <category term="arxiv" scheme="http://nysdy.com/tags/arxiv/"/>
    
  </entry>
  
  <entry>
    <title>Transition-based Knowledge Graph Embedding with Relational Mapping Properties阅读笔记</title>
    <link href="http://nysdy.com/post/Transition-based_Knowledge_Graph_Embedding_with_Relational_Mapping_Properties/"/>
    <id>http://nysdy.com/post/Transition-based_Knowledge_Graph_Embedding_with_Relational_Mapping_Properties/</id>
    <published>2019-08-31T13:36:06.000Z</published>
    <updated>2019-09-15T13:59:40.912Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pdfs.semanticscholar.org/0ddd/f37145689e5f2899f8081d9971882e6ff1e9.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="2014" scheme="http://nysdy.com/tags/2014/"/>
    
  </entry>
  
  <entry>
    <title>Embedding Edge-attributed Relational Hierarchies阅读笔记</title>
    <link href="http://nysdy.com/post/Embedding_Edge-attributed_Relational_Hierarchies/"/>
    <id>http://nysdy.com/post/Embedding_Edge-attributed_Relational_Hierarchies/</id>
    <published>2019-08-28T08:12:30.000Z</published>
    <updated>2019-08-28T08:15:05.849Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://yellowstone.cs.ucla.edu/~muhao/articles/_SIGIR__hre.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Knowledge Graph Embedding via Dynamic Mapping Matrix阅读笔记</title>
    <link href="http://nysdy.com/post/Knowledge_Graph_Embedding_via_Dynamic_Mapping_Matrix/"/>
    <id>http://nysdy.com/post/Knowledge_Graph_Embedding_via_Dynamic_Mapping_Matrix/</id>
    <published>2019-08-24T11:58:52.000Z</published>
    <updated>2019-08-28T04:58:45.444Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;论文下载地址&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="TransD" scheme="http://nysdy.com/tags/TransD/"/>
    
  </entry>
  
  <entry>
    <title>From Knowledge Graph Embedding to Ontology Embedding  An Analysis of the Compatibility between Vector Space Representations and Rules阅读笔记</title>
    <link href="http://nysdy.com/post/From_Knowledge_Graph_Embedding_to_Ontology_Embedding_An_Analysis_of_the_Compatibility_between_Vector_Space_Representations_and_Rules/"/>
    <id>http://nysdy.com/post/From_Knowledge_Graph_Embedding_to_Ontology_Embedding_An_Analysis_of_the_Compatibility_between_Vector_Space_Representations_and_Rules/</id>
    <published>2019-07-25T08:57:55.000Z</published>
    <updated>2019-07-25T09:04:31.963Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;论文下载地址&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Knowledge graph embedding with concepts阅读笔记</title>
    <link href="http://nysdy.com/post/Knowledge_graph_embedding_with_concepts/"/>
    <id>http://nysdy.com/post/Knowledge_graph_embedding_with_concepts/</id>
    <published>2019-07-25T05:19:44.000Z</published>
    <updated>2020-03-25T14:12:06.667Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇论文，运用skip-gram方法，将实体对应相关概念引入实体向量表示，以增强表示效果。实体和概念在同一空间中，但是概念是空间中的一个超平面（类似于transH）。文中举例很多例子来辅助说明，使得文章可读性大幅提升。文中实验最后俩个比较有意思。本文值得思考借鉴的东西不少，值得再好好回顾。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0950705118304945/pdfft?md5=b9bad12f2bc771990ad0feaefa7402d4&amp;amp;pid=1-s2.0-S0950705118304945-main.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="ontology" scheme="http://nysdy.com/tags/ontology/"/>
    
      <category term="concept" scheme="http://nysdy.com/tags/concept/"/>
    
  </entry>
  
  <entry>
    <title>Universal Representation Learning of Knowledge Bases by Jointly Embedding Instances and Ontological Concepts阅读笔记</title>
    <link href="http://nysdy.com/post/Universal_Representation_Learning_of_Knowledge_Bases_by_Jointly_Embedding_Instances_and_Ontological_Concepts/"/>
    <id>http://nysdy.com/post/Universal_Representation_Learning_of_Knowledge_Bases_by_Jointly_Embedding_Instances_and_Ontological_Concepts/</id>
    <published>2019-07-17T08:45:52.000Z</published>
    <updated>2019-07-25T08:41:32.245Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://web.cs.ucla.edu/~yzsun/papers/2019_KDD_JOIE.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="ontology" scheme="http://nysdy.com/tags/ontology/"/>
    
  </entry>
  
  <entry>
    <title>DocRED A Large-Scale Document-Level Relation Extraction Dataset阅读笔记</title>
    <link href="http://nysdy.com/post/DocRED_A_Large-Scale_Document-Level_Relation_Extraction_Dataset/"/>
    <id>http://nysdy.com/post/DocRED_A_Large-Scale_Document-Level_Relation_Extraction_Dataset/</id>
    <published>2019-07-01T01:11:49.000Z</published>
    <updated>2019-07-01T01:49:37.278Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;这是一个介绍数据集的论文，主要是文档级别的关系抽取数据集。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1906.06127&quot; target=&quot;_blank&quot;
        
      
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="RE" scheme="http://nysdy.com/tags/RE/"/>
    
      <category term="dataset" scheme="http://nysdy.com/tags/dataset/"/>
    
  </entry>
  
  <entry>
    <title>Learning Entity and Relation Embeddings for Knowledge Graph Completion阅读笔记</title>
    <link href="http://nysdy.com/post/Learning_Entity_and_Relation_Embeddings_for_Knowledge_Graph_Completion/"/>
    <id>http://nysdy.com/post/Learning_Entity_and_Relation_Embeddings_for_Knowledge_Graph_Completion/</id>
    <published>2019-06-26T08:18:15.000Z</published>
    <updated>2019-06-27T07:51:44.136Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;TransR embeds entities and relations in distinct entity space and relation space, and learns embeddings via translation between projected entities.CTransR models internal complicated correlations within each relation type.&lt;/p&gt;
&lt;p&gt;论文下载地址&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="KGR" scheme="http://nysdy.com/tags/KGR/"/>
    
      <category term="TransR" scheme="http://nysdy.com/tags/TransR/"/>
    
  </entry>
  
  <entry>
    <title>Neural Relation Extraction with Selective Attention over Instances阅读笔记</title>
    <link href="http://nysdy.com/post/Neural_Relation_Extraction_with_Selective_Attention_over_Instances/"/>
    <id>http://nysdy.com/post/Neural_Relation_Extraction_with_Selective_Attention_over_Instances/</id>
    <published>2019-06-26T05:49:57.000Z</published>
    <updated>2019-06-26T08:12:44.937Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章之前看过😂。&lt;/p&gt;
&lt;p&gt;论下载地址&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="RE" scheme="http://nysdy.com/tags/RE/"/>
    
  </entry>
  
  <entry>
    <title>Learning as the Unsupervised Alignment of Conceptual Systems阅读笔记</title>
    <link href="http://nysdy.com/post/Learning_as_the_Unsupervised_Alignment_of_Conceptual_Systems/"/>
    <id>http://nysdy.com/post/Learning_as_the_Unsupervised_Alignment_of_Conceptual_Systems/</id>
    <published>2019-06-25T06:42:57.000Z</published>
    <updated>2019-06-26T04:02:25.369Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章没怎么看懂，主要思想应该是代表同时概念的不同形式（文本，图像，语音等）应该具有相似的分布，以此来进行无监督的概念对齐。这种思路挺不错的，不过还没有深入的想法，算是拓展视野吧！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>ERNIE Enhanced Language Representation with Informative Entities阅读笔记</title>
    <link href="http://nysdy.com/post/ERNIE_Enhanced_Language_Representation_with_Informative_Entities/"/>
    <id>http://nysdy.com/post/ERNIE_Enhanced_Language_Representation_with_Informative_Entities/</id>
    <published>2019-06-24T03:10:26.000Z</published>
    <updated>2019-06-25T06:32:57.460Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;该篇论文借鉴BERT，试图将实体信息（TransE）融入token(singal word)中，通过类似实体对齐的方法将实体与token对齐（并采取mask方式进行预训练），通过infromation fusion 将token与实体融合映射入相关联的两个向量空间。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1905.07129&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGR" scheme="http://nysdy.com/tags/KGR/"/>
    
      <category term="BERT" scheme="http://nysdy.com/tags/BERT/"/>
    
      <category term="KG" scheme="http://nysdy.com/tags/KG/"/>
    
  </entry>
  
  <entry>
    <title>Incorporating Literals into Knowledge Graph Embeddings阅读笔记</title>
    <link href="http://nysdy.com/post/Incorporating_Literals_into_Knowledge_Graph_Embeddings/"/>
    <id>http://nysdy.com/post/Incorporating_Literals_into_Knowledge_Graph_Embeddings/</id>
    <published>2019-06-03T06:57:50.000Z</published>
    <updated>2019-06-03T07:33:16.832Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;读完了前两章，简单的看了一下作者提出的模型，感觉并没有太大价值，就是给实体输入多加入了一个literal的信息（加入方法可以采用线性、非线性或者神经网络）。&lt;/p&gt;
&lt;p&gt;读论文前需要先熟悉DistMult、ComlLEx和ConvE模型，此论文方
        
      
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="link prediction" scheme="http://nysdy.com/tags/link-prediction/"/>
    
  </entry>
  
  <entry>
    <title>Learning Knowledge Embeddings by Combining Limit-based Scoring Loss阅读笔记</title>
    <link href="http://nysdy.com/post/Learning_Knowledge_Embeddings_by_Combining_Limit-based_Scoring_Loss/"/>
    <id>http://nysdy.com/post/Learning_Knowledge_Embeddings_by_Combining_Limit-based_Scoring_Loss/</id>
    <published>2019-06-03T02:57:20.000Z</published>
    <updated>2019-06-03T03:06:20.944Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;此篇文章最为重要的就是作者设计的 margin-based ranking loss 的改进，对两个超参数$\lambda$和$\gamma$的实验，对于实验结果有很多值得分析与思考的地方。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/ft_gateway.cfm?id=3132939&amp;amp;ftid=1920664&amp;amp;dwn=1&amp;amp;CFID=135630312&amp;amp;CFTOKEN=71536805165d7c9d-10D2074A-AD9B-A596-5CA31DB63C36A322&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KG" scheme="http://nysdy.com/tags/KG/"/>
    
      <category term="transH" scheme="http://nysdy.com/tags/transH/"/>
    
      <category term="margin loss" scheme="http://nysdy.com/tags/margin-loss/"/>
    
      <category term="transE" scheme="http://nysdy.com/tags/transE/"/>
    
  </entry>
  
  <entry>
    <title>Knowledge Graph Embedding by Translating on Hyperplanes阅读笔记</title>
    <link href="http://nysdy.com/post/Knowledge%20Graph%20Embedding%20by%20Translating%20on%20Hyperplanes/"/>
    <id>http://nysdy.com/post/Knowledge Graph Embedding by Translating on Hyperplanes/</id>
    <published>2019-05-28T08:17:44.000Z</published>
    <updated>2019-06-01T05:38:20.042Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;作为trans系列经典文献，必读。文章主要精华在于这种超平面想法的由来解决了同一实体的多关系问题。&lt;/p&gt;
&lt;p&gt;Authors proposed TransH which models a relation as a hyperplane together with a translation operation on it. It solves the problem of multi-relation and makes a good trade-off between model capacity and efficiency.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="KG" scheme="http://nysdy.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/KG/"/>
    
    
      <category term="KGE" scheme="http://nysdy.com/tags/KGE/"/>
    
      <category term="transH" scheme="http://nysdy.com/tags/transH/"/>
    
  </entry>
  
</feed>
