<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NYSDY</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-28T06:45:06.501Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>NYSDY</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Attention Is All You Need阅读笔记</title>
    <link href="http://yoursite.com/post/Attention%20Is%20All%20You%20Need/"/>
    <id>http://yoursite.com/post/Attention Is All You Need/</id>
    <published>2019-05-25T05:57:35.000Z</published>
    <updated>2019-05-28T06:45:06.501Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>transformer 是一个完全由注意力机制组成的搭建的模型，模型复杂度低，并可以进行并行计算，使得计算速度快。在翻译模型上取得了较好的效果。本篇论文属于经典必读论文，阅读笔记中对一些不清楚的地方进行了汉语解释，读完论文后阅读参考链接以加深理解。</p><p><a href="https://arxiv.org/pdf/1706.03762" target="_blank" rel="noopener">论文下载地址</a></p></blockquote><a id="more"></a><h1 id="research-objective"><a href="#research-objective" class="headerlink" title="research objective"></a>research objective</h1><p>based solely on attention mechanisms, increase parallezable computation and decrease train time</p><h1 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h1><p>recurrent models hidden states depended on previous hidden state and the input for position precludes parallelization</p><h1 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h1><ul><li>Transformer,<ul><li>eschewing recurrence and instead relying entirely on an attention mechanism, solve the long dependency problem.</li><li>draw global dependecies between input and output </li><li>allow for significantly more parallelization</li></ul></li></ul><h1 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h1><p>The Transformer uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder.<img src="http://image.nysdy.com/2019052515587656321218.jpg" alt="2019052515587656321218.jpg"></p><h2 id="Encoder-and-Decoder-Stacks"><a href="#Encoder-and-Decoder-Stacks" class="headerlink" title="Encoder and Decoder Stacks"></a>Encoder and Decoder Stacks</h2><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul><li>compose of a stack of N identical layers</li><li>each layers has two sub-layers<ol><li>multi-head self-attention mechanism</li><li>position-wise fully connected feed forward network</li></ol></li><li>employ a residual connection around each of the two sub-layers, followed by layer normalization</li><li>the output of each sub-layer is $\text { LayerNorm }(x+\text { Sublayer }(x))$</li><li>encoder中的Q，K，V都是学出来的</li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><ul><li>composed of a stack of N identical layers</li><li>has the same two sub-layers as the encoder</li><li>the third sub-layer between the two sub-layers<ul><li>perform multi-head attention over the output of the encoder stack</li></ul></li><li>add a mask to modify the self-attention sub-layer to ensure that the predictions for position $i$ can depend only the known outputs at positions less than $i$</li><li>除了第一子层中Q，K，V是自己学出来的，第二个子层利用了encoder中的K，V。</li></ul><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p><img src="http://image.nysdy.com/20190526155885488441950.jpg" alt="20190526155885488441950.jpg"></p><h3 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h3><p>the calculation process as the left at the figure 2. <strong>formula：</strong></p><script type="math/tex; mode=display">\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V</script><ul><li>where $\sqrt{d_{k}}$ is to  prevent value from getting too large, which will push the softmax function into regions where it has extremely small gradients. 因为量级太大，softmax后就非0即1了，不够“soft”了。也会导致softmax的梯度非常小。也就是让softmax结果<strong>不稀疏</strong>(问号脸，通常人们希望得到更稀疏的attention吧)。</li><li>$Q, K,V$ is a matrix needed to learn from input.</li></ul><h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p><strong>helps the encoder look at other words in the input sentence as it encodes a specific word</strong></p><p>in the figure 2 right. </p><ul><li>it’s beneficial to <strong>lineraly project</strong> the quries, keys and values $h$ times with different, learned projections to $d_k, d_k, d_v$ dimensions, respectively</li><li>concatenate the output </li></ul><script type="math/tex; mode=display">\begin{aligned} \text { MultiHead }(Q, K, V) &=\text { Concat (head }_{1}, \ldots, \text { head }_{h} ) W^{O} \\ \text { where head }_{i} &=\text { Attention }\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right) \end{aligned}</script><p>where $W_{i}^{Q} \in \mathbb{R}^{d_{\text { model }} \times d_{k}}, W_{i}^{K} \in \mathbb{R}^{d_{\text { model }} \times d_{k}}, W_{i}^{V} \in \mathbb{R}^{d_{\text { model }} \times d_{v}}, W^{O} \in \mathbb{R}^{h d_{v} \times d_{\mathrm{model}}}$</p><h3 id="Applications-of-Attention-in-our-Model"><a href="#Applications-of-Attention-in-our-Model" class="headerlink" title="Applications of Attention in our Model"></a>Applications of Attention in our Model</h3><ul><li>the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. mimicing the seq-to-seq</li><li>self -attention can make that each position in the encoder can attend to all positions in the previous layer of the encoder</li><li><strong>We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2</strong>。即我们只能attend到前面已经翻译过的输出的词语，因为翻译过程我们当前还并不知道下一个输出词语，这是我们之后才会推测到的。即将$QK^T$中每行该单词之后的数值做处理，使得前面的单词看不到后面单词所占的重要性程度。</li></ul><h2 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h2><ul><li>applied to each position separately and identically</li><li>feed-forward network consists of tow linear transformations with a ReLU activation. formula:</li></ul><script type="math/tex; mode=display">\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}</script><blockquote><p><strong>小结</strong></p><ol><li>为什么叫强调<code>position-wise</code>?<ul><li>解释一: 这里FFN层是每个position进行相同且独立的操作，所以叫position-wise。对每个position独立做FFN。</li><li>解释二：从卷积的角度解释，这里的FFN等价于kernel_size=1的卷积，这样每个position都是独立运算的。如果kernel_size=2，或者其他，position之间就具有依赖性了，貌似就不能叫做position-wise了</li></ul></li><li>为什么要采用全连接层？<ul><li>目的: 增加非线性变换</li><li>如果不采用FFN呢？有什么替代的设计？</li></ul></li><li>为什么采用2层全连接，而且中间升维？<ul><li>这也是所谓的bottle neck，只不过低维在IO上，中间采用high rank</li></ul></li></ol></blockquote><h2 id="Embeddings-and-Softmax"><a href="#Embeddings-and-Softmax" class="headerlink" title="Embeddings and Softmax"></a>Embeddings and Softmax</h2><p>Sharing the same weight maatrix between the two embedding layers and the pre-softmax linear transformation</p><h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>Using sine and xosine functions of different frequencies:</p><script type="math/tex; mode=display">P E_{(p o s, 2 i)}=\sin \left(p o s / 10000^{2 i / d_{\text { model }}}\right)\\P E_{(p o s, 2 i+1)}=\cos \left(p o s / 10000^{2 i / d_{\mathrm{model}}}\right)</script><ul><li><p>where $pos$ is the postiiton and $i$ is the dimension</p></li><li><p><strong>Authors hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset $k$, $PE_{pos+k}$can be represented as a linear function of $PE_{pos}$</strong></p><p>但在语言中，<code>相对位置</code>也很重要，Google选择前述的位置向量公式的一个重要原因是：由于我们有$\sin (\alpha+\beta)=\sin \alpha \cos \beta+\cos \alpha \sin \beta$以及$\cos (\alpha+\beta)=\cos \alpha \cos \beta-\sin \alpha \sin \beta$，这表明位置$p+k$的向量可以表示成位置$p$的向量的线性变换，这提供了表达相对位置信息的可能性。</p></li><li><p>Compared with using learned positional embeddings, the sinusoidal version may allow the model to extrapolate to sequence lengths longer than the ones encountered during training.</p></li></ul><p>注意由于该模型没有recurrence或convolution操作，所以没有明确的关于单词在源句子中位置的相对或绝对的信息，为了更好的让模型学习位置信息，所以添加了position encoding并将其叠加在word embedding上。</p><h1 id="Why-Self-Attention"><a href="#Why-Self-Attention" class="headerlink" title="Why Self-Attention"></a>Why Self-Attention</h1><ul><li>total computational complexity per layer</li><li>the amount of computation that can be parallelized</li><li>the path between long-range dependencies in the network</li></ul><p><img src="http://image.nysdy.com/20190527155892126287777.jpg" alt="20190527155892126287777.jpg"></p><p><img src="http://image.nysdy.com/20190528155902465937774.jpg" alt="20190528155902465937774.jpg"></p><p>self-attention|：</p><ul><li>$QK^TV$相乘，根据矩阵大小（分别为$n<em>d, n</em>d, n<em>d$需要的复杂度为$O(n^2d</em>2)$（忽略softmax）</li><li>maximum path length：图说明了， 对于self-attention, target node (生成的那个点) 实际上和 输入中的任意一点的距离是相同的</li></ul><p>convolutional:  </p><ul><li><p>每层有k个卷积和，对于input matix（$n<em>d$)矩阵执行卷积需要运算复杂度是$n</em>d*(d-m)$, m为卷积和宽度是一个比较小的常数，所以总复杂度为$O\left(k \cdot n \cdot d^{2}\right)$,作者提到可分离的卷基层暂时还不了解，可以以后查阅。</p></li><li><p>maximum path length: 正常卷积和的距离是$O(n/k)$, 但如果是堆叠卷积如图：　　<img src="http://image.nysdy.com/2019052815590251436862.jpg" alt="2019052815590251436862.jpg"></p><p>就可以减小到$O\left(\log _{k}(n)\right)$</p></li></ul><p>recurrent:</p><ul><li>计算是每个词向量乘隐藏权重($d*d$)，所以易得计算复杂度：$O\left(n \cdot d^{2}\right)$</li><li>maximum path length: 长度就是n。</li><li>操作步骤要从第一个到第n个为n步，是有顺序的。其他的都没有顺序要求</li></ul><p>self-attentin(restricted)</p><ul><li>相当于只输入r邻近的句子长度，自然可以得到如图结果</li></ul><h1 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h1><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><script type="math/tex; mode=display">\text { lrate }=d_{\text { model }}^{-0.5} \cdot \min \left(\text {step}_{-} n u m^{-0.5}, \text { step }_{-} n u m \cdot \text { warmup steps }^{-1.5}\right)</script><ul><li>increasing the learning rate linearly for the first warmup_steps training steps</li><li>decreasing it thereafter proportionally to the inverse square root of the step number</li></ul><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="Residual-Dropout"><a href="#Residual-Dropout" class="headerlink" title="Residual Dropout"></a>Residual Dropout</h3><ul><li>apply dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized</li><li>apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks</li></ul><h3 id="Label-Smoothing"><a href="#Label-Smoothing" class="headerlink" title="Label Smoothing"></a>Label Smoothing</h3><ul><li>This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score</li></ul><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><h2 id="machine-Translation"><a href="#machine-Translation" class="headerlink" title="machine Translation"></a>machine Translation</h2><p>Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the competitive models</p><p><img src="http://image.nysdy.com/2019052715589406009133.jpg" alt="2019052715589406009133.jpg"></p><h2 id="Model-Variations"><a href="#Model-Variations" class="headerlink" title="Model Variations"></a>Model Variations</h2><p><img src="http://image.nysdy.com/20190527155894062794865.jpg" alt="20190527155894062794865.jpg"></p><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a><strong>缺点</strong></h1><p>缺点在原文中没有提到，是后来在Universal Transformers中指出的，在这里加一下吧，主要是两点：</p><ol><li>实践上：有些rnn轻易可以解决的问题transformer没做到，比如复制string，尤其是碰到比训练时的sequence更长的时</li><li>理论上：transformers非computationally universal（<a href="https://www.zhihu.com/question/20115374/answer/288346717" target="_blank" rel="noopener">图灵完备</a>），（我认为）因为无法实现“while”循环</li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1><p>Transformer是第一个用纯attention搭建的模型，不仅计算速度更快，在翻译任务上也获得了更好的结果。</p><p>Google现在的翻译应该是在此基础上做的，但是数据量大可能用transformer好一些，小的话还是继续用rnn-based model。</p><p>花了不少时间，算是理解了attention和transformer，对其中不是很清楚的点如attention的内部中Q，K，V具体是什么在self-attention和multi-head attention中大小是不同的，如何mask，如何计算复杂，等进行查阅资料弄懂了。总体来说还是收获很大的。准备在看一些代码讲解。</p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li>Attention机制详解（二）——Self-Attention与Transformer - 川陀学者的文章 - 知乎<br><a href="https://zhuanlan.zhihu.com/p/47282410" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47282410</a></li><li><strong><a href="https://jalammar.github.io/illustrated-transformer/（这个讲的比较详细，建议看完论文后再看一遍这个会加深理解）" target="_blank" rel="noopener">https://jalammar.github.io/illustrated-transformer/（这个讲的比较详细，建议看完论文后再看一遍这个会加深理解）</a></strong></li><li>【NLP】Transformer详解 - 李如的文章 - 知乎<br><a href="https://zhuanlan.zhihu.com/p/44121378" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/44121378</a></li><li><a href="https://blog.eson.org/pub/664e9bad/" target="_blank" rel="noopener">https://blog.eson.org/pub/664e9bad/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;transformer 是一个完全由注意力机制组成的搭建的模型，模型复杂度低，并可以进行并行计算，使得计算速度快。在翻译模型上取得了较好的效果。本篇论文属于经典必读论文，阅读笔记中对一些不清楚的地方进行了汉语解释，读完论文后阅读参考链接以加深理解。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.03762&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
      <category term="attention" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/attention/"/>
    
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
      <category term="translation" scheme="http://yoursite.com/tags/translation/"/>
    
      <category term="classical" scheme="http://yoursite.com/tags/classical/"/>
    
  </entry>
  
  <entry>
    <title>Graph Neural Networks with Generated Parameters for Relation Extraction阅读笔记</title>
    <link href="http://yoursite.com/post/Graph_Neural_Networks_with_Generated_Parameters_for_Relation/"/>
    <id>http://yoursite.com/post/Graph_Neural_Networks_with_Generated_Parameters_for_Relation/</id>
    <published>2019-05-23T02:41:51.000Z</published>
    <updated>2019-05-23T09:24:39.487Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文将GNNs应用到处理非结构化文本的（多跳）关系推理任务来进行关系抽取。采用从句子序列中获取的实体构建全链接图，应用编码（sequence model），传播（节点间信息）和分类（预测）三个模块来处理关系推理。本文提供了三个数据集。</p></blockquote><a id="more"></a><h1 id="problem-statement"><a href="#problem-statement" class="headerlink" title="problem statement"></a>problem statement</h1><ul><li>existing relation extraction models fail to infer the relationship without multi-hop relational reasoning.</li><li>existing GNNs can’t process multi-hop relational reasoning in natural language relational reasoning </li></ul><h1 id="research-objective"><a href="#research-objective" class="headerlink" title="research objective"></a>research objective</h1><p>enable GNNs to porcess relational reasoning on unstructed text inputs</p><h1 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h1><ul><li>extend a GNN with generated parameters, which could be applied to process relational reasoning on unstructured inputs</li><li>verify GP-GNNs in the taks of relation extraction from text; present three datasets</li></ul><h1 id="GP-GNNs"><a href="#GP-GNNs" class="headerlink" title="GP-GNNs"></a>GP-GNNs</h1><ul><li>construct a fully-connected graph with the entities in the sequence of text</li><li>employs three models to process relational reasoning<ul><li>an encoding modul: enable edges to encode rich information from natural languages </li><li>a propagation modul: propagates realtional information among various nodes </li><li>a classification modul: make prediction with node representations </li></ul></li></ul><p>As compared to tradtional GNNs, GP-GNNs could learn edges’ parameters from natural lanuages</p><h1 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h1><h2 id="Graph-Neural-Networks-GNNs"><a href="#Graph-Neural-Networks-GNNs" class="headerlink" title="Graph Neural Networks(GNNs)"></a>Graph Neural Networks(GNNs)</h2><ul><li>existing models still perfom message-passing on predefined graphs</li><li><em>Learning Graphical State Transitions</em> is most related<ul><li>introduecs a nove lnerual architecture to generate a graph based on the textal input</li><li>dynamically update the relationship during the learning process</li></ul></li></ul><h2 id="relational-reasoning"><a href="#relational-reasoning" class="headerlink" title="relational reasoning"></a>relational reasoning</h2><ul><li>existing models could not make full use of the multi-hop inference patterns among multiple entity pair and their relaitons within the sentence </li><li><em>LEARNING GRAPHICAL STATE TRANSITIONS</em> is the most related work<ul><li>the proposed model incorporates contextual relations with attention mechanism when predicting the relation of a target entity pair</li></ul></li></ul><h1 id="Graph-Neural-Network-with-Grenerated-Parameters-GP-GNNs"><a href="#Graph-Neural-Network-with-Grenerated-Parameters-GP-GNNs" class="headerlink" title="Graph Neural Network with Grenerated Parameters(GP-GNNs)"></a>Graph Neural Network with Grenerated Parameters(GP-GNNs)</h1><p>The picture is overall architecture: encoding module, propagation module and classification module</p><p><img src="http://image.nysdy.com/20190523155858968594021.jpg" alt="20190523155858968594021.jpg"></p><h2 id="Encoding-Module"><a href="#Encoding-Module" class="headerlink" title="Encoding Module"></a>Encoding Module</h2><p>formula:</p><script type="math/tex; mode=display">\mathcal{A}_{i, j}^{(n)}=f\left(E\left(x_{0}^{i, j}\right), E\left(x_{1}^{i, j}\right), \cdots, E\left(x_{l-1}^{i, j}\right) ; \theta_{e}^{n}\right)</script><p>where $f(\cdot)$ could be any model that could sequential(such as LSTMs); $E(\cdot)$ indicates an embedding function. $x^{i, j}$ is the word in sentence labeled( $i,j$)</p><h2 id="Porpagation-Module"><a href="#Porpagation-Module" class="headerlink" title="Porpagation Module"></a>Porpagation Module</h2><p>the representations of layer n + 1 are calculated by:</p><script type="math/tex; mode=display">\mathbf{h}_{i}^{(n+1)}=\sum_{v_{j} \in \mathcal{N}\left(v_{i}\right)} \sigma\left(\mathcal{A}_{i, j}^{(n)} \mathbf{h}_{j}^{(n)}\right)</script><p>where $\mathcal{N}\left(v_{i}\right)$ denotes the neighbors of node $v_i$</p><h2 id="Classification-Module"><a href="#Classification-Module" class="headerlink" title="Classification Module"></a>Classification Module</h2><p>the loss of GP-GNNs:</p><script type="math/tex; mode=display">\mathcal{L}=g\left(\mathbf{h}_{0 :|\mathcal{V}|-1}^{0}, \mathbf{h}_{0 :|\mathcal{V}|-1}^{1}, \ldots, \mathbf{h}_{0 :|\mathcal{V}|-1}^{K}, Y ; \theta_{c}\right)</script><h1 id="Relation-Extraction-with-GP-GNNs"><a href="#Relation-Extraction-with-GP-GNNs" class="headerlink" title="Relation Extraction with GP-GNNs"></a>Relation Extraction with GP-GNNs</h1><p>Authors introduce how to apply GP-GNNs to relation extraction</p><h2 id="Encoding-Module-1"><a href="#Encoding-Module-1" class="headerlink" title="Encoding Module"></a>Encoding Module</h2><p>encoding then context of entity pairs (or edges in the graph)</p><script type="math/tex; mode=display">E\left(x_{t}^{i, j}\right)=\left[\boldsymbol{x}_{t} ; \boldsymbol{p}_{t}^{i, j}\right]</script><p>where $x_t$ denotes the word embedding; $\boldsymbol{p}_{t}^{i, j}$denotes the position embedding of word posistion t relative to the entity pair’s position $i, j$.</p><h3 id="position-embedding"><a href="#position-embedding" class="headerlink" title="position embedding"></a>position embedding</h3><p>we mark each token in the sentence as either belonging to the first entity $v_i$, the second entity $v_j$ or to neither of those</p><h2 id="Propagation-Module"><a href="#Propagation-Module" class="headerlink" title="Propagation Module"></a>Propagation Module</h2><p> the formula is the same as the front</p><h3 id="The-Initial-Embeddings-of-Nodes"><a href="#The-Initial-Embeddings-of-Nodes" class="headerlink" title="The Initial Embeddings of Nodes"></a>The Initial Embeddings of Nodes</h3><ul><li>when extracting the relationship between entity $v_i$ and entity $v_j$, the initial embeddings of them are annotated as $\mathbf{h}_{v_{i}}^{(0)}=a_{\text { subject }}$, and $h_{v_{j}}^{(0)}=a_{\text { object }}$, while the intial embeddings of other entities are set to all zeros.</li><li>In our experiments, we generalize the idea of Gated Graph Neural Networks (Li et al., 2016) by setting $a_{\text { subject }}=[1 ; 0]^{\top}$and $a_{\text { object }}=[0 ; 1]^{\top}$.</li></ul><h2 id="classification-Module"><a href="#classification-Module" class="headerlink" title="classification Module"></a>classification Module</h2><p><strong>As the  target entity pair $(v_i, v_j)$:</strong></p><script type="math/tex; mode=display">\boldsymbol{r}_{v_{i}, v_{j}}=\left[\left[\boldsymbol{h}_{v_{i}}^{(1)} \odot \boldsymbol{h}_{v_{j}}^{(1)}\right]^{\top} ;\left[\boldsymbol{h}_{v_{i}}^{(2)} \odot \boldsymbol{h}_{v_{j}}^{(2)}\right]^{\top} ; \ldots ;\left[\boldsymbol{h}_{v_{i}}^{(K)} \odot \boldsymbol{h}_{v_{j}}^{(K)}\right]^{\top}\right]</script><p>where $\odot$ represents element-wise multiplication</p><p><strong>classification:</strong></p><script type="math/tex; mode=display">\mathbb{P}\left(r_{v_{i}, v_{j}} | h, t, s\right)=\operatorname{softmax}\left(M L P\left(\boldsymbol{r}_{v_{i}, v_{j}}\right)\right)</script><p><strong>loss:</strong></p><script type="math/tex; mode=display">\mathcal{L}=\sum_{s \in S} \sum_{i \neq j} \log \mathbb{P}\left(r_{v_{i}, v_{j}} | i, j, s\right)</script><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="aim"><a href="#aim" class="headerlink" title="aim"></a>aim</h2><ul><li>showing their best models could improve the performance of relation extraction under a variety of settings</li><li>illlustrating that how the number of layers affect the performance of their model</li><li>performing a qualitiative investigation to highlight the diference between their models and baseline models</li></ul><h2 id="design"><a href="#design" class="headerlink" title="design"></a>design</h2><p>as the first and second aim</p><ul><li>show that our models could improve instance-level relation extraction on a human annotated test set</li><li>we will show that our models could also help enhance the performance of bag-level relation extraction on a distantly labeled test set</li><li>split a subset of distantly labeled test set, where the number of entities and edges is large</li></ul><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><h3 id="distantly-label-set"><a href="#distantly-label-set" class="headerlink" title="distantly label set"></a>distantly label set</h3><ul><li>Sorokin and Gurevych (2017) proposed </li><li>modify their dataset<ul><li>added reversed edges</li><li>for all of the entity pairs with no relations, added “NA” labels to them</li></ul></li></ul><h3 id="Human-annotated-test-set"><a href="#Human-annotated-test-set" class="headerlink" title="Human annotated test set"></a>Human annotated test set</h3><ul><li>Sorokin and Gurevych (2017)</li><li>select the distantly lablel pairs which all 5 annotaters are accepted.</li><li>There are 350 sentences and 1,230 triples in this test set </li></ul><h3 id="Dense-distantly-labeled-test-set"><a href="#Dense-distantly-labeled-test-set" class="headerlink" title="Dense distantly labeled test set"></a>Dense distantly labeled test set</h3><ul><li>criteria<ul><li>the number of entities should be strictly larger than 2</li><li>there must be at least one circle (with at least three entities) in the ground-truth label of the sentence</li></ul></li><li>There are 1,350 sentences and more than 17,915 triples and 7,906 relational facts in this test set.</li></ul><h2 id="Models-for-comparison"><a href="#Models-for-comparison" class="headerlink" title="Models for comparison"></a>Models for comparison</h2><ul><li>Context-aware RE</li><li>Multi-Window CNN</li><li>PCNN</li><li>LSTM or GP-GNN with K = 1 layer</li><li>GP-GNN with K = 2 or K = 3 layerss</li></ul><h2 id="Evaluation-Details"><a href="#Evaluation-Details" class="headerlink" title="Evaluation Details"></a>Evaluation Details</h2><p><strong>To evaluation models in bag-level:</strong></p><script type="math/tex; mode=display">E\left(r | v_{i}, v_{j}, S\right)=\max _{s \in S} \mathbb{P}\left(r_{v_{i}, v_{j}} | i, j, s\right)</script><p><strong>result</strong>:</p><p><img src="http://image.nysdy.com/20190523155859369893411.jpg" alt="20190523155859369893411.jpg"></p><h2 id="Effectiveness-of-Reasoning-Mechanism"><a href="#Effectiveness-of-Reasoning-Mechanism" class="headerlink" title="Effectiveness of Reasoning Mechanism"></a>Effectiveness of Reasoning Mechanism</h2><p><img src="http://image.nysdy.com/2019052315585938129506.jpg" alt="2019052315585938129506.jpg"></p><ul><li>Context-Aware RE may <strong>introduce more noise,</strong> for it may mistakenly increase the probability of a relation with the similar topic with the context relations</li><li>sentences from Wikipedia corpus are always complex, which may be hard to model for CNN and PCNN</li></ul><h2 id="The-Effectiveness-of-the-Number-of-Layers"><a href="#The-Effectiveness-of-the-Number-of-Layers" class="headerlink" title="The Effectiveness of the Number of Layers"></a>The Effectiveness of the Number of Layers</h2><p><img src="http://image.nysdy.com/20190523155859455443298.jpg" alt="20190523155859455443298.jpg"></p><ul><li>the improvement of the third layer is much smaller on the overall distantly supervised test set than the one on the dense subset<ul><li>This observation reveals that the reasoning mechanism could help us identify relations especially on sentences where there are more entities</li></ul></li><li>as the number of layers grows, the curves get higher and higher precision, <ul><li>indicating considering more hops in reasoning leads to better performance</li></ul></li></ul><h2 id="Qualitative-Results-Case-Study"><a href="#Qualitative-Results-Case-Study" class="headerlink" title="Qualitative Results: Case Study"></a>Qualitative Results: Case Study</h2><p><img src="http://image.nysdy.com/20190523155859457710223.jpg" alt="20190523155859457710223.jpg"></p><p>Context-Aware RE makes a mistake by predicting (Kentucky, share boarder with, Ohio). As we have discussed before, this is due to its mechanism to model co-occurrence of multiple relations</p><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>文章是刘知远组的论文，针对的方向是关系抽取，在其中结合了关系推理，最近许多任务都在结合推理的思想。文章整体的结构，逻辑十分清晰，论述的也比较详细，属于标准论文。感觉文章中GP-GNNs结构图还可以画的更好一点，展现一下encoding module的层，可以更好理解。文章的精髓应该是这个propagation module的部分，还需要消化一下，不过这部分可能是有先前的知识支撑的。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文将GNNs应用到处理非结构化文本的（多跳）关系推理任务来进行关系抽取。采用从句子序列中获取的实体构建全链接图，应用编码（sequence model），传播（节点间信息）和分类（预测）三个模块来处理关系推理。本文提供了三个数据集。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="GNNs" scheme="http://yoursite.com/tags/GNNs/"/>
    
      <category term="relation extraction" scheme="http://yoursite.com/tags/relation-extraction/"/>
    
      <category term="relation reasoning" scheme="http://yoursite.com/tags/relation-reasoning/"/>
    
  </entry>
  
  <entry>
    <title>allennlp安装踩坑</title>
    <link href="http://yoursite.com/post/allennlp_install/"/>
    <id>http://yoursite.com/post/allennlp_install/</id>
    <published>2019-05-22T14:09:27.000Z</published>
    <updated>2019-05-22T14:11:19.740Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>安装allennlp的踩坑之路，踩了不少坑最后选择’Installing from source’的安装方法，排坑后下面方法亲测可用</p></blockquote><a id="more"></a><h2 id="Installing-from-source"><a href="#Installing-from-source" class="headerlink" title="Installing from source"></a>Installing from source</h2><p>安装步骤：</p><h3 id="1-下载GitHub文件"><a href="#1-下载GitHub文件" class="headerlink" title="1.下载GitHub文件"></a>1.下载GitHub文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/allenai/allennlp.git</span><br></pre></td></tr></table></figure><h3 id="2-创建conda环境"><a href="#2-创建conda环境" class="headerlink" title="2.创建conda环境"></a>2.创建conda环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n allennlp python=3.6</span><br></pre></td></tr></table></figure><h3 id="3-激活环境下载依赖文件"><a href="#3-激活环境下载依赖文件" class="headerlink" title="3.激活环境下载依赖文件"></a>3.激活环境下载依赖文件</h3><ul><li><p>激活环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate allennlp</span><br></pre></td></tr></table></figure></li><li><p>进入github上下载的文件夹</p></li><li><p>下载依赖文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>遇到报错问题，参考下一小节，所欲问题解决。</p></li></ul><h3 id="4-安装allennlp"><a href="#4-安装allennlp" class="headerlink" title="4.安装allennlp"></a>4.安装allennlp</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --editable .</span><br></pre></td></tr></table></figure><h3 id="5-测试"><a href="#5-测试" class="headerlink" title="5.测试"></a>5.测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp</span><br></pre></td></tr></table></figure><p>成功后效果如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> allennlp</span><br><span class="line">2019-05-22 21:58:42,297 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .</span><br><span class="line">usage: allennlp</span><br><span class="line"></span><br><span class="line">Run AllenNLP</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help     show this help message and exit</span><br><span class="line">  --version      show program's version number and exit</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line"></span><br><span class="line">    configure    Run the configuration wizard.</span><br><span class="line">    train        Train a model.</span><br><span class="line">    evaluate     Evaluate the specified model + dataset.</span><br><span class="line">    predict      Use a trained model to make predictions.</span><br><span class="line">    make-vocab   Create a vocabulary.</span><br><span class="line">    elmo         Create word vectors using a pretrained ELMo model.</span><br><span class="line">    fine-tune    Continue training a model on a new dataset.</span><br><span class="line">    dry-run      Create a vocabulary, compute dataset statistics and other</span><br><span class="line">                 training utilities.</span><br><span class="line">    test-install</span><br><span class="line">                 Run the unit tests.</span><br><span class="line">    find-lr      Find a learning rate range.</span><br><span class="line">    print-results</span><br><span class="line">                 Print results from allennlp serialization directories to the</span><br><span class="line">                 console.</span><br></pre></td></tr></table></figure><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><h4 id="报错信息："><a href="#报错信息：" class="headerlink" title="报错信息："></a>报错信息：</h4><p>ERROR: Failed building wheel for jsonnet</p><p><img src="http://image.nysdy.com/20190522155853293350470.jpg" alt="20190522155853293350470.jpg"></p><h4 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge jsonnet</span><br></pre></td></tr></table></figure><h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><h4 id="报错信息：-1"><a href="#报错信息：-1" class="headerlink" title="报错信息："></a>报错信息：</h4><p>报的都是某些包的版本问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ERROR: botocore 1.12.152 has requirement urllib3&lt;1.25,&gt;=1.20; python_version &gt;= "3.4", but you'll have urllib3 1.25.2 which is incompatible.</span><br><span class="line">ERROR: aws-sam-translator 1.11.0 has requirement jsonschema~=2.6, but you'll have jsonschema 3.0.1 which is incompatible.</span><br><span class="line">ERROR: cfn-lint 0.20.3 has requirement jsonschema~=2.6, but you'll have jsonschema 3.0.1 which is incompatible.</span><br><span class="line">ERROR: cfn-lint 0.20.3 has requirement requests&lt;=2.21.0,&gt;=2.15.0, but you'll have requests 2.22.0 which is incompatible</span><br></pre></td></tr></table></figure><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><p>根据报错信息下载相应安装包即可</p><h2 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h2><h4 id="报错信息：-2"><a href="#报错信息：-2" class="headerlink" title="报错信息："></a>报错信息：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ImportError: dlopen: cannot load any more object with static TLS</span><br><span class="line">___________________________________________________________________________</span><br><span class="line">Contents of /home/minelab/anaconda3/envs/allennlp/lib/python3.6/site-packages/sklearn/__check_build:</span><br><span class="line">__init__.py               setup.py                  _check_build.cpython-36m-x86_64-linux-gnu.so</span><br><span class="line">__pycache__</span><br><span class="line">___________________________________________________________________________</span><br><span class="line">It seems that scikit-learn has not been built correctly.</span><br><span class="line"></span><br><span class="line">If you have installed scikit-learn from source, please do not forget</span><br><span class="line">to build the package before using it: run `python setup.py install` or</span><br><span class="line">`make` in the source directory.</span><br><span class="line"></span><br><span class="line">If you have used an installer, please check that it is suited for your</span><br><span class="line">Python version, your operating system and your platform.</span><br></pre></td></tr></table></figure><h4 id="解决方法：-1"><a href="#解决方法：-1" class="headerlink" title="解决方法："></a>解决方法：</h4><p>下载更低版本的scikit-learn,例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-learn=0.20.3</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/pytorch/pytorch/issues/10443" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/10443</a></li><li><a href="https://github.com/pypa/pip/issues/4330" target="_blank" rel="noopener">https://github.com/pypa/pip/issues/4330</a></li></ul><h1 id="安装的启示"><a href="#安装的启示" class="headerlink" title="安装的启示"></a>安装的启示</h1><h3 id="环境问题"><a href="#环境问题" class="headerlink" title="环境问题"></a>环境问题</h3><ul><li>最基本的就是先去网上查这个错误的解决方法</li><li>网上的解决不了的，先猜猜大概率是哪方面的问题。<ul><li>比如大概率是各种版本互相之间不适配的问题，那就调试版本，一般都会告诉你哪个有问题，比如上面的scikit-learn问题。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;安装allennlp的踩坑之路，踩了不少坑最后选择’Installing from source’的安装方法，排坑后下面方法亲测可用&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="install" scheme="http://yoursite.com/categories/install/"/>
    
    
      <category term="allennlp" scheme="http://yoursite.com/tags/allennlp/"/>
    
      <category term="包安装" scheme="http://yoursite.com/tags/%E5%8C%85%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>Triple Trustworthiness Measurement for Knowledge Graph阅读笔记</title>
    <link href="http://yoursite.com/post/Triple%20Trustworthiness%20Measurement%20for%20Knowledge%20Graph/"/>
    <id>http://yoursite.com/post/Triple Trustworthiness Measurement for Knowledge Graph/</id>
    <published>2019-05-21T06:45:26.000Z</published>
    <updated>2019-05-22T13:33:20.088Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文提出了一种通过计算triple trustworthiness来评估知识图谱的准确程度的方法。模型利用神经网络综合来自实体（借鉴Resource allocation）、关系（借鉴翻译模型的思想，如TransE）和KG全局（借鉴关系路径，RNN）三个层面的语义和全局信息，输出最后的 trustworthiness作为判断依据。</p><p><a href="http://delivery.acm.org/10.1145/3320000/3313586/p2865-jia.pdf?ip=59.64.129.22&amp;id=3313586&amp;acc=OPEN&amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1558515578_57e0bf75d529cf4656975ffe7da506b9" target="_blank" rel="noopener">下载地址</a></p></blockquote><a id="more"></a><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>This paper proposed a method for estimating the accuracy of a knowledge graph by computing triple trustworthiness. The model uses neural network to synthesize semantic and global information from three levels: entity(resource allocation), relationship(translation model ideas, such as TransE)m and KG global(relationship path, RNN) and outputting the final trustworthiness as the basis for judgment.</p><h1 id="Problem-statement"><a href="#Problem-statement" class="headerlink" title="Problem statement"></a>Problem statement</h1><p>possible noises and conflicts are inevitably intoduced in the process of constructing the KG</p><h1 id="research-objective"><a href="#research-objective" class="headerlink" title="research objective"></a>research objective</h1><p>quantify the KG’s semantic correctness and the true degree of the facts expressed</p><h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><ul><li>Knowledge graph triple trustworthiness measurement<ul><li>use the  triple semantic information and globally inferring information</li><li>three levels measurement and an intergration of confidence value</li></ul></li><li>experiment result verified the model valid on large-scale KG Freebase</li><li>the KGTtm could be utilized in knowledge graph construction or improvement</li></ul><h1 id="THE-TRIPLE-TRUSTWORTHINESS-MEASUREMENT-MODEL"><a href="#THE-TRIPLE-TRUSTWORTHINESS-MEASUREMENT-MODEL" class="headerlink" title="THE TRIPLE TRUSTWORTHINESS MEASUREMENT MODEL"></a>THE TRIPLE TRUSTWORTHINESS MEASUREMENT MODEL</h1><p><img src="http://image.nysdy.com/20190521155842605796518.jpg" alt="20190521155842605796518.jpg"></p><ul><li>Longitudinally, the model can be divided into two level.<ul><li>the upper is a pool of multiple trustworthiness estimate cells(estimator)</li><li>the output of these Estimator forms the input of lower-level fusion device(Fusioner)</li></ul></li><li>Viewed laterally, three progressive levels   are be considered, as following.</li></ul><h2 id="Is-there-a-possible-relationship-between-the-entity-pairs"><a href="#Is-there-a-possible-relationship-between-the-entity-pairs" class="headerlink" title="Is there a possible relationship between the entity pairs?"></a>Is there a possible relationship between the entity pairs?</h2><p><img src="http://image.nysdy.com/20190521155842810227816.jpg" alt="20190521155842810227816.jpg"></p><p>ResourceRank:</p><ul><li>The algorithm assumes that the association between entity paires $(h,t)$ will be stronger, and more resource is passed from the  head $h$ through all associated paths to the tail $t$ in a graph</li><li>The amount of resource aggregated into $t$ ingeniously indicateds the association strength from $h$ to $t$.</li></ul><p>As pair $(e_1,e_2)$, there only one directed edge from $e_1$ to $e_2$ in the graph, where the different bandwidth of the edge indicates the number of the multiple relations.</p><p>output:</p><script type="math/tex; mode=display">\left\{\begin{array}{c}{u=\alpha\left(W_{1} V+b_{1}\right)} \\ {R R(h, t)=W_{2} u+b_{2}}\end{array}\right.</script><p>Authors constructed a $V$ vector by combining six characteristics.</p><ol><li>R (t | h); </li><li>In-degree of head node ID(h); </li><li>Out-degree of head node OD(h); </li><li>In-degree of tail node ID(t);</li><li>Out-degree of tail node OD(t);</li><li>The depth from head node to tail node Dep</li></ol><p>As for 1. the formula:</p><script type="math/tex; mode=display">R(t | h)=(1-\theta) \sum_{e_{i} \in M_{t}} \frac{R\left(e_{i} | h\right) \cdot B W_{e_{i} t}}{O D\left(e_{i}\right)}+\frac{\theta}{N}</script><ul><li>$M_t$is the set of all nodes that have outgoing links to the node $t$, $OD (e_i)$ is the out-degree of the node eiand the $BW_{e_it}$ is the bandwidth from the $e_i$ to $t$.</li><li>In order to improve the model fault-tolerance, we assume that the resource fow from each node may directly jump to a random node with the same probability θ</li></ul><h2 id="Can-the-determined-relationship-r-occur-between-the-entity-pair-h-t"><a href="#Can-the-determined-relationship-r-occur-between-the-entity-pair-h-t" class="headerlink" title="Can the determined relationship $r$ occur between the entity pair $(h,t)$ ?"></a>Can the determined relationship $r$ occur between the entity pair $(h,t)$ ?</h2><p><img src="http://image.nysdy.com/20190522155850919251079.jpg" alt="20190522155850919251079.jpg"></p><p>Translation-based energy function (TEF)：depended on TransE</p><p>$E(h, r, t)=|\mathbf{h}+\mathbf{r}-\mathbf{t}|$</p><p>output:</p><script type="math/tex; mode=display">P(E(h, r, t))=\frac{1}{1+e^{-\lambda\left(\delta_{r}-E(h, r, t)\right)}}</script><h2 id="Can-the-relevant-triples-in-the-KG-infer-that-the-triple-is-trustworthy"><a href="#Can-the-relevant-triples-in-the-KG-infer-that-the-triple-is-trustworthy" class="headerlink" title="Can the relevant triples in the KG infer that the triple is trustworthy?"></a>Can the relevant triples in the KG infer that the triple is trustworthy?</h2><p><img src="http://image.nysdy.com/20190522155851013726520.jpg" alt="20190522155851013726520.jpg"></p><p>Reachable paths inference (RPI):</p><p>There two challenges to exploit the reachable paths for inferring triple trustworthiness:</p><h3 id="reachable-paths-selection"><a href="#reachable-paths-selection" class="headerlink" title="reachable paths selection"></a>reachable paths selection</h3><p>Semantic distance-based path selection<img src="http://image.nysdy.com/2019052215585105592950.jpg" alt="2019052215585105592950.jpg"></p><h3 id="Reachable-Paths-Representation"><a href="#Reachable-Paths-Representation" class="headerlink" title="Reachable Paths Representation"></a>Reachable Paths Representation</h3><p>using a RNN to deal with the embeddings of the three elements of each triple in the selected path</p><h2 id="Fusing-the-Estimators"><a href="#Fusing-the-Estimators" class="headerlink" title="Fusing the Estimators"></a>Fusing the Estimators</h2><p>a classifer based on a multi-layer perceptron </p><h1 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h1><h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><p>FB15K</p><h2 id="Interpreting-the-Validity-of-the-Trustworthiness"><a href="#Interpreting-the-Validity-of-the-Trustworthiness" class="headerlink" title="Interpreting the Validity of the Trustworthiness"></a>Interpreting the Validity of the Trustworthiness</h2><p><img src="http://image.nysdy.com/20190522155851139148623.jpg" alt="20190522155851139148623.jpg"></p><ul><li>The left picture shows that the positives examples are mainly concentrated in the upper region, vice versa.</li><li>As for the right picture<ul><li>only if the value of a triple is higher than the threshold can it be considered trustworthy</li><li>shows that the positive examples universally have higher confidence values</li></ul></li></ul><h2 id="Comparing-With-Other-Models-on-The-Knowledge-Graph-Error-Detection-Task"><a href="#Comparing-With-Other-Models-on-The-Knowledge-Graph-Error-Detection-Task" class="headerlink" title="Comparing With Other Models on The Knowledge Graph Error Detection Task"></a>Comparing With Other Models on The Knowledge Graph Error Detection Task</h2><p><img src="http://image.nysdy.com/20190522155851269267340.jpg" alt="20190522155851269267340.jpg"></p><p>Authors’ model has beter results in terms of accuracy and the F1-score than the other models.</p><h2 id="Analyzing-the-ability-of-models-to-tackle-the-three-type-noises"><a href="#Analyzing-the-ability-of-models-to-tackle-the-three-type-noises" class="headerlink" title="Analyzing the ability of models to tackle the three type noises."></a>Analyzing the ability of models to tackle the three type noises.</h2><p><img src="http://image.nysdy.com/20190522155851290149973.jpg" alt="20190522155851290149973.jpg"></p><ul><li>a higher recall shows that authors’ model can more accurately find the right from noisy triples</li><li>higher average trustworthiness values show that authors’ model can better identify the correct instances and with high confidence </li><li>the worst among the $(h, ?, t)$, because the various relations between a certain entity  increase the difficulty of model judgment.</li></ul><h2 id="Analyzing-the-Efects-of-Single-Estimators"><a href="#Analyzing-the-Efects-of-Single-Estimators" class="headerlink" title="Analyzing the Efects of Single Estimators"></a>Analyzing the Efects of Single Estimators</h2><p><img src="http://image.nysdy.com/20190522155851337652153.jpg" alt="20190522155851337652153.jpg"></p><p>It can be found that the accuracy obtained by each model is above 0.8, which proves the effectiveness of each Estimator</p><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>本文在方法上几乎没有什么创新，本质上就是一个老方法的多个组合。最大亮点就是作者能提出trustworthiness来把这个评价知识图谱准确度的问题进行了量化。这种能力比提出方法上的创新更加厉害，也是需要学习的地方。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文提出了一种通过计算triple trustworthiness来评估知识图谱的准确程度的方法。模型利用神经网络综合来自实体（借鉴Resource allocation）、关系（借鉴翻译模型的思想，如TransE）和KG全局（借鉴关系路径，RNN）三个层面的语义和全局信息，输出最后的 trustworthiness作为判断依据。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/3320000/3313586/p2865-jia.pdf?ip=59.64.129.22&amp;amp;id=3313586&amp;amp;acc=OPEN&amp;amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;amp;__acm__=1558515578_57e0bf75d529cf4656975ffe7da506b9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Knowledge Graph" scheme="http://yoursite.com/tags/Knowledge-Graph/"/>
    
      <category term="KG" scheme="http://yoursite.com/tags/KG/"/>
    
      <category term="Triple" scheme="http://yoursite.com/tags/Triple/"/>
    
  </entry>
  
  <entry>
    <title>GloVe: Global Vectors for Word Representation阅读笔记</title>
    <link href="http://yoursite.com/post/GloVe:Global%20Vectors%20for%20Word%20Representation/"/>
    <id>http://yoursite.com/post/GloVe:Global Vectors for Word Representation/</id>
    <published>2019-05-20T13:35:25.000Z</published>
    <updated>2019-05-21T06:43:45.987Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>论文<a href="https://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">下载地址</a>，GloVe是一个新的全球对数双线性回归模型，属于经典的词向量表示方法之一。</p></blockquote><a id="more"></a><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>evaluate the intrinsic quality</p><ul><li>Most word vector methods rely on the distance or angle between pairs of word vectors </li><li>Mikolov et al. (2013c) introduced word analogies that examines word vector’s various dimensions of difference.</li></ul><p>two main model families for learning vectors:</p><ul><li>global matrix factorization methods</li><li>local context window methods</li></ul><p>Authors propose a specific weighted least squares model that trains on globla word-word co-occurrence counts and thus makes efficient use of statistics.</p><h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="Matix-Facroization-Methods"><a href="#Matix-Facroization-Methods" class="headerlink" title="Matix Facroization Methods"></a>Matix Facroization Methods</h2><p>These methods utilize low-rank approximations to decompose large matrices that capture statistical information about a corpus.</p><h3 id="shortcoming"><a href="#shortcoming" class="headerlink" title="shortcoming"></a>shortcoming</h3><p>the most frequent words contribute a dispropoertionate amount to the similarity measure.</p><h2 id="Shallow-Window-Based-Methods"><a href="#Shallow-Window-Based-Methods" class="headerlink" title="Shallow Window-Based Methods"></a>Shallow Window-Based Methods</h2><p>Another approach is to learn word representations that aid in making predictins within local context windows.</p><h3 id="shortcoming-1"><a href="#shortcoming-1" class="headerlink" title="shortcoming"></a>shortcoming</h3><p>do not operate directly on the co-occurrence statistics of the corpus and fails to take advantage of the vast amount of repetition in the data.</p><h1 id="The-GloVe-Model"><a href="#The-GloVe-Model" class="headerlink" title="The GloVe Model"></a>The GloVe Model</h1><h3 id="GloVe-Global-Vectors"><a href="#GloVe-Global-Vectors" class="headerlink" title="GloVe: Global Vectors"></a>GloVe: Global Vectors</h3><p>the global corpus statistics are captured directly by the model</p><h3 id="the-question-about-the-model-using-the-statistics-of-word-occurrences-in-a-corpus"><a href="#the-question-about-the-model-using-the-statistics-of-word-occurrences-in-a-corpus" class="headerlink" title="the question about the model using the statistics of word occurrences in a corpus"></a>the question about the model using the statistics of word occurrences in a corpus</h3><ul><li>how meaning is generated from these statistics</li><li>how the resulting word vectors might represent that meaning</li></ul><h2 id="some-notation"><a href="#some-notation" class="headerlink" title="some notation"></a>some notation</h2><p>$X_{ij}$ : the number of times word j occurs in the context of word i</p><p>$X_i = \sum_{k} X_{i k}$ : the number of times any word appears in the context of word i</p><p>$P_{i j}=P(j | i)=X_{i j} / X_{i}$: the probability that word j appear in the context of word i</p><p><img src="http://image.nysdy.com/20190515155788329289127.jpg" alt="20190515155788329289127.jpg"></p><p>above that, werd vector learning should be with ratios of co-occurrence probabilities:</p><p><img src="http://image.nysdy.com/20190515155788352871603.jpg" alt="20190515155788352871603.jpg"></p><p>$w \in \mathbb{R}^{d}$are word vectors and $\tilde{w} \in \mathbb{R}^{d}$are separate context word vectors</p><p>For F, we should select a unique choice by enforcing a few desiderata.</p><ul><li><p>encoding the information present the ratio $P_{i k} / P_{j k}$ in the word vector space. </p><p>Since vector spaces are inherently linear structures</p><p><img src="http://image.nysdy.com/20190515155788379647745.jpg" alt="20190515155788379647745.jpg"></p></li><li><p>put F to be a compicated function parameterized, and avoiding bofuscating the linear structure<img src="http://image.nysdy.com/20190515155788397136355.jpg" alt="20190515155788397136355.jpg"></p></li><li><p>the word-word co-occurrence matrices, we can exchange a word and a context word(because a word can also be a context word)</p><ol><li><p>F should be a homomorphism<img src="http://image.nysdy.com/2019051515578842869345.jpg" alt="2019051515578842869345.jpg"></p><p>by Eqn.(3)<img src="http://image.nysdy.com/20190515155788435674239.png" alt="20190515155788435674239.png"></p><p>F = exp or <img src="http://image.nysdy.com/20190515155788448759173.jpg" alt="20190515155788448759173.jpg"></p></li><li><p>the Eqn(6) would have the exchange symmetry if not $\log \left(X_{i}\right)$ and $\log \left(X_{i}\right)$ is independent of k, so it can be absorbed into a bias $b_i$<img src="http://image.nysdy.com/20190515155788566687599.jpg" alt="20190515155788566687599.jpg"></p></li><li><p>for avoiding diverge, $\log \left(X_{i k}\right) \rightarrow \log \left(1+X_{i k}\right)$</p></li><li><p>a new weighted least squares regression model to address the problem that LSA wirhts all co-occuttences equally.</p><p>cost function:<img src="http://image.nysdy.com/20190515155788560186237.jpg" alt="20190515155788560186237.jpg"></p></li><li><p><img src="http://image.nysdy.com/20190515155788571777804.jpg" alt="20190515155788571777804.jpg"></p></li></ol></li></ul><h2 id="Relationship-to-Other-Models"><a href="#Relationship-to-Other-Models" class="headerlink" title="Relationship to Other Models"></a>Relationship to Other Models</h2><p>In this subsection authors show how these models are related to their proposed model.</p><h4 id="the-defect-of-cross-entropy"><a href="#the-defect-of-cross-entropy" class="headerlink" title="the defect of cross entropy"></a>the defect of cross entropy</h4><ul><li>it has the unfortunate property that distributions with long tails are often modeled poorly with too much wieght given to the unlikely events.</li></ul><h2 id="Complexity-of-the-model"><a href="#Complexity-of-the-model" class="headerlink" title="Complexity of the model"></a>Complexity of the model</h2><p>the computational complexity of the model depends on the number of nonzero elects in the matrix $X$</p><h4 id="some-assumptions-about-the-distribution-of-word-co-occurrences"><a href="#some-assumptions-about-the-distribution-of-word-co-occurrences" class="headerlink" title="some assumptions about the distribution of word co-occurrences"></a>some assumptions about the distribution of word co-occurrences</h4><ul><li><p>the number of co-occurrences of word $i$ with word $j$, $X_{ij}$, can be modeled as a power-law function of the frequency rank of that word pair, $r_{ij}$:</p><p>$X_{i j}=\frac{k}{\left(r_{i j}\right)^{\alpha}}$</p></li></ul><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Evaluation-methods"><a href="#Evaluation-methods" class="headerlink" title="Evaluation methods"></a>Evaluation methods</h2><p>authors conduct experiments on the word analogy taks of Mikolov et al. (2013a)</p><h3 id="Word-analogies"><a href="#Word-analogies" class="headerlink" title="Word analogies"></a>Word analogies</h3><p>The word analogy task consists of questions like, “a is to b as c is to ?”</p><h3 id="Word-similarity"><a href="#Word-similarity" class="headerlink" title="Word similarity"></a>Word similarity</h3><p><img src="http://image.nysdy.com/20190520155833277478435.jpg" alt="20190520155833277478435.jpg"></p><h3 id="Named-entity-recognition"><a href="#Named-entity-recognition" class="headerlink" title="Named entity recognition"></a>Named entity recognition</h3><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>Table 2 shows the CloVe model performs significantly better than the other baslines, often with smaller vector sizes and smaller corpora.</p><p><img src="http://image.nysdy.com/20190520155833353468570.jpg" alt="20190520155833353468570.jpg"></p><p>Table 3 shows results on five different word similarity datasets.</p><p>Table 4 shows results on the NER task with the CRF-based model.</p><p><img src="http://image.nysdy.com/20190520155833377540169.jpg" alt="20190520155833377540169.jpg"></p><h2 id="Model-Analysis-Vector-Length-and-Context-Size"><a href="#Model-Analysis-Vector-Length-and-Context-Size" class="headerlink" title="Model Analysis: Vector Length and Context Size"></a>Model Analysis: Vector Length and Context Size</h2><p><img src="http://image.nysdy.com/2019052015583339399087.jpg" alt="2019052015583339399087.jpg"></p><h3 id="Model-Analysis-Corpus-Size"><a href="#Model-Analysis-Corpus-Size" class="headerlink" title="Model Analysis: Corpus Size"></a>Model Analysis: Corpus Size</h3><p><img src="http://image.nysdy.com/20190520155833403240640.jpg" alt="20190520155833403240640.jpg"></p><ul><li>On the syntactic subtask, larger corpora typically produce better statistics so that there is a monotonic increase in performance as the cor- pus size increases.</li><li>But the same trend is not true for the semantic subtask, which is probably because of analogy dataset</li></ul><h2 id="Model-Analysis-Run-time"><a href="#Model-Analysis-Run-time" class="headerlink" title="Model Analysis: Run-time"></a>Model Analysis: Run-time</h2><p><img src="http://image.nysdy.com/20190520155833432462881.jpg" alt="20190520155833432462881.jpg"></p><h2 id="Model-Analysis-Comparison-with-word2vec"><a href="#Model-Analysis-Comparison-with-word2vec" class="headerlink" title="Model Analysis: Comparison with word2vec"></a>Model Analysis: Comparison with word2vec</h2><p>For the same corpus, vocabulary, window size, and training time, GloVe consistently outperforms word2vec</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://blog.csdn.net/coderTC/article/details/73864097" target="_blank" rel="noopener">https://blog.csdn.net/coderTC/article/details/73864097</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;论文&lt;a href=&quot;https://www.aclweb.org/anthology/D14-1162&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载地址&lt;/a&gt;，GloVe是一个新的全球对数双线性回归模型，属于经典的词向量表示方法之一。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="word vector" scheme="http://yoursite.com/tags/word-vector/"/>
    
      <category term="GloVe" scheme="http://yoursite.com/tags/GloVe/"/>
    
  </entry>
  
  <entry>
    <title>Deep contextualized word representations 阅读笔记</title>
    <link href="http://yoursite.com/post/Deep%20contextualized%20word%20representations/"/>
    <id>http://yoursite.com/post/Deep contextualized word representations/</id>
    <published>2019-05-10T07:28:06.000Z</published>
    <updated>2019-05-13T06:50:58.808Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">论文下载地址</a>，ELMo事先用语言模型学好一个单词的 Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用 Word Embedding 的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义去调整单词的 Word Embedding 表示，这样经过调整后的 Word Embedding 更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。<strong>所以 ELMO 本身是个根据当前上下文对 Word Embedding 动态调整的思路。</strong></p></blockquote><a id="more"></a><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="ELMo-Embedddings-from-Language-Models"><a href="#ELMo-Embedddings-from-Language-Models" class="headerlink" title="ELMo(Embedddings from Language Models):"></a>ELMo(Embedddings from Language Models):</h2><h3 id="why-call-ELMo"><a href="#why-call-ELMo" class="headerlink" title="why call ELMo:"></a>why call ELMo:</h3><p>Using vectors derived from a bidirectional LSTM that is trained with a coupled language model(LM) objective on a large text corups.</p><h3 id="characteristics"><a href="#characteristics" class="headerlink" title="characteristics"></a>characteristics</h3><ul><li><p>ELMo representations are a function of all of the internal layers of the biLM.</p></li><li><p>learn a linear combination of the vectors stacked above each input word for each end task</p></li><li><p>the higher-level LSTM states capture context-dependent aspects of word meaning</p><p>the lower-level states model aspects of syntax</p></li></ul><h3 id="Extensive-experiments"><a href="#Extensive-experiments" class="headerlink" title="Extensive experiments"></a>Extensive experiments</h3><ul><li>EMLo representations can be easily added to existing models</li><li>improve the state of art in every case</li><li>ELMo outperform those derived from just the top layer of a LSTM</li></ul><h1 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h1><ul><li><p>Some approaches for learning word vectors only allow a single context-independent representation for each word.</p></li><li><p>to overcome some shortcomings of traditional word vectors:</p><ul><li>enriching them with subword information</li><li>learning separate vectors for each word sense</li></ul><p>Authors uses subword units through the use of character convolutions, seamlessly incorporate multi-sense information into downstream tasks without explicitly training to predict predefined sense classes.</p></li><li><p>context-depends representations</p><p> Authors take full advantage of access to plentiful monolingual data</p></li><li><p>Previous work also shown that different layers of deep biRNNs encode different types of information</p><ul><li>introducing multi-task syntactic supervision at the lower levels of a deep LSTM can improve overall performance of higher level tasks</li><li>the top layer of an LSTM for encoding word context (Melamud et al., 2016) has been shown to learn representations of word sense.</li></ul><p>ELMo representations can also induce similar signals.</p></li></ul><h1 id="ELMo-Embeddings-from-Language-Models"><a href="#ELMo-Embeddings-from-Language-Models" class="headerlink" title="ELMo: Embeddings from Language Models"></a>ELMo: Embeddings from Language Models</h1><h2 id="Bidirectional-language-models"><a href="#Bidirectional-language-models" class="headerlink" title="Bidirectional language models"></a>Bidirectional language models</h2><ul><li><p>model the probability of token $t_k$ given the history($t_1, … , t_{k-1}$):</p><p><img src="http://image.nysdy.com/20190512155766627486478.png" alt="20190512155766627486478.png"></p></li><li><p>a backward LM:<img src="http://image.nysdy.com/2019051215576663543534.png" alt="2019051215576663543534.png"></p></li></ul><p>Authors’ formulation jointly maximizes the log likelihood of the forward and backward directions:</p><p><img src="http://image.nysdy.com/20190512155766643539454.png" alt="20190512155766643539454.png"></p><h2 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h2><ul><li><p>For each token $t_k$, a L-layer biLM computes a set of 2L + 1 representations:<img src="http://image.nysdy.com/20190512155767113638451.png" alt="20190512155767113638451.png"></p></li><li><p>For a downstream model, ELMo collapses all layers in R into a single vector.</p><p>In the simplest case, ELMo just selects the top layer.</p></li><li><p>For a task specific weighting of all biLM layers:<img src="http://image.nysdy.com/20190512155767132777658.png" alt="20190512155767132777658.png"></p><p>$s^{task}$ are softmax-normalized weithts and the scalar parameter $γ^{task}$ allows the task model to scale the entire ELMo vector</p></li></ul><h2 id="Using-biLMs-for-supervised-NLP-tasks"><a href="#Using-biLMs-for-supervised-NLP-tasks" class="headerlink" title="Using biLMs for supervised NLP tasks"></a>Using biLMs for supervised NLP tasks</h2><ul><li>Given a pre-trained biLM and a supervised architecture for a target NLP task</li><li>let the end task model learn a linear combination of these representations<ol><li>consider the lowest layers of th supervised model without the biLM</li><li>add ELMo to the supervised model<ul><li>freeze the weights of the biLM</li><li>concatenate the ELMo vector $ELMo^{task}_k$ with $x_k$ and pass the ELMo enhanced representation $[x_k,;ELMo^{task}_k ]$ into the task RNN.</li><li>for some tasks, authors also include ELMo ar the output of task RNN by introducing another set of out put specific linear weights and replacing $h_k$ with $[h_k,;ELMo^{task}_k ]$</li><li>add a moderate amount of dropout to ELMo and in some case to regularize the ELMo weights</li></ul></li></ol></li></ul><h2 id="Pre-trained-bidirectional-language-model-architecture"><a href="#Pre-trained-bidirectional-language-model-architecture" class="headerlink" title="Pre-trained bidirectional language model architecture"></a>Pre-trained bidirectional language model architecture</h2><ul><li>the biLM provides three layers of representations for each input token, both directions and a residual connection between LSTM layers </li><li>fine tuning the biLM on domain specific data</li></ul><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>the following picture shows the performance of ELMo in Question answering, Textual entailment, Semantic role labeling, Corefrence resolution, Named entity extraction, Sentiment analysis.</p><p><img src="http://image.nysdy.com/2019051315577106394943.png" alt="2019051315577106394943.png"></p><p>In every task considered, simply adding ELMo establishes a new state-of-the-art result.</p><h1 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h1><h2 id="Alternate-layer-weighting-schemes"><a href="#Alternate-layer-weighting-schemes" class="headerlink" title="Alternate layer weighting schemes"></a>Alternate layer weighting schemes</h2><p><img src="http://image.nysdy.com/20190512155767132777658.png" alt="20190512155767132777658.png"></p><p>the following picture compares these alternatives.</p><p><img src="http://image.nysdy.com/20190513155771140936480.png" alt="20190513155771140936480.png"></p><p>Including representations from all layers improves overall performance over just using the last layer, and including contextual representations from the last layer improves performace over the baseline.</p><p>Also shows the $\lambda$ is important.</p><h2 id="Where-to-include-ELMo"><a href="#Where-to-include-ELMo" class="headerlink" title="Where to include ELMo?"></a>Where to include ELMo?</h2><p>The ELMo can be included in both the input and output.</p><p><img src="http://image.nysdy.com/20190513155771190646517.png" alt="20190513155771190646517.png"></p><p>the results show including the ELMo in both input and output can preform better.</p><h2 id="What-information-is-captured-by-the-biLM’s-representations"><a href="#What-information-is-captured-by-the-biLM’s-representations" class="headerlink" title="What information is captured by the biLM’s representations?"></a>What information is captured by the biLM’s representations?</h2><p>Intuitively, the biLM must be disambiguating the meaning of words using their context.<img src="http://image.nysdy.com/20190513155771262634271.png" alt="20190513155771262634271.png"></p><p>The GloVe can only capure the speech. but the biLM is able to disambiguate both the part of speech and word sense in the source sentence.</p><h3 id="Word-sense-disambiguation"><a href="#Word-sense-disambiguation" class="headerlink" title="Word sense disambiguation"></a>Word sense disambiguation</h3><p>given a sentence, predicting  the sense of a target word using a simple 1-nearst negihbor approach</p><p><img src="http://image.nysdy.com/20190513155771312514655.png" alt="20190513155771312514655.png"></p><h3 id="POS-tagging"><a href="#POS-tagging" class="headerlink" title="POS tagging"></a>POS tagging</h3><p>to examine whether the biLM captures basic syntax.</p><p><img src="http://image.nysdy.com/20190513155771328944169.png" alt="20190513155771328944169.png"></p><h2 id="Sample-efficiency"><a href="#Sample-efficiency" class="headerlink" title="Sample efficiency"></a>Sample efficiency</h2><p>Adding ELMo to a model increases the sample efficiency considerably, both in terms of number of parameter updates to reach state-of-the-art performance and the overall training set size.<img src="http://image.nysdy.com/20190513155771349825964.png" alt="20190513155771349825964.png"></p><h2 id="Visualization-of-learned-weights"><a href="#Visualization-of-learned-weights" class="headerlink" title="Visualization of learned weights"></a>Visualization of learned weights</h2><p><img src="http://image.nysdy.com/20190513155771355211483.png" alt="20190513155771355211483.png"></p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/63115885" target="_blank" rel="noopener">NAACL2018:高级词向量(ELMo)详解(超详细) 经典</a>，这篇文章中阐述了一些使用的细节，并用图来表示，更加清晰。</li><li><a href="https://blog.csdn.net/triplemeng/article/details/82380202" target="_blank" rel="noopener">ELMo算法介绍</a>，这篇博客中自己对整个论文的概述和总结和好，需要学习。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.05365.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，ELMo事先用语言模型学好一个单词的 Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用 Word Embedding 的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义去调整单词的 Word Embedding 表示，这样经过调整后的 Word Embedding 更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。&lt;strong&gt;所以 ELMO 本身是个根据当前上下文对 Word Embedding 动态调整的思路。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="embedding" scheme="http://yoursite.com/tags/embedding/"/>
    
  </entry>
  
  <entry>
    <title>《Efficient Estimation of Word Representations in Vector Space》阅读笔记</title>
    <link href="http://yoursite.com/post/Efficient%20Estimation%20of%20Word%20Representations%20in%20Vector%20Space/"/>
    <id>http://yoursite.com/post/Efficient Estimation of Word Representations in Vector Space/</id>
    <published>2019-04-30T02:37:23.000Z</published>
    <updated>2019-05-06T09:00:22.589Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener">论文下载地址</a>，该篇论文的大篇幅都在讨论实验结果的分析，模型的部分比较简单，没有详细分析，本来是想读一下CBOW和skip-gram的原始论文，发现并没有想象中的那么大的用处。</p></blockquote><a id="more"></a><h2 id="Goals-of-paper"><a href="#Goals-of-paper" class="headerlink" title="Goals of paper"></a>Goals of paper</h2><ul><li>开发了两种新模型，并保留了单词之间的线性规律</li><li>设计了一个新的综合测试集，用于测量句法和语义规律</li><li>讨论了训练时间和准确性如何取决于单词向量的维度和训练数据的数量</li></ul><h2 id="Model-Architectures"><a href="#Model-Architectures" class="headerlink" title="Model Architectures"></a>Model Architectures</h2><p>训练复杂度：</p><p><img src="http://image.nysdy.com/20190506155712909488421.png" alt="20190506155712909488421.png"></p><p>其中，E是训练次数，T是训练集单词数量，Q是模型结构。</p><h3 id="Feedforward-Neural-Net-Language-Model-NNLM"><a href="#Feedforward-Neural-Net-Language-Model-NNLM" class="headerlink" title="Feedforward Neural Net Language Model (NNLM)"></a>Feedforward Neural Net Language Model (NNLM)</h3><p>它由输入，映射，隐藏和输出层组成。通过简化方法，Q= N x D x H</p><h3 id="Recurrent-Neural-Net-Language-Model-RNNLM"><a href="#Recurrent-Neural-Net-Language-Model-RNNLM" class="headerlink" title="Recurrent Neural Net Language Model (RNNLM)"></a>Recurrent Neural Net Language Model (RNNLM)</h3><p>克服了模型需要固定的上下文长度的问题，并且只有输入，隐藏和输出层。</p><p>Q= H x H + H x V，其中H = D（单词表示），H x V 可以通过分级softmax被简化为H x log_2(V)。所以主要的复杂度来自于H x H。</p><h3 id="Parallel-Training-of-Neural-Networks"><a href="#Parallel-Training-of-Neural-Networks" class="headerlink" title="Parallel Training of Neural Networks"></a>Parallel Training of Neural Networks</h3><p>模型使用的DistBelief框架允许我们并行运行同一模型的多个副本，每个副本通过集中的服务器同步其梯度更新，该服务器保留所有参数</p><h2 id="New-Log-linear-Models"><a href="#New-Log-linear-Models" class="headerlink" title="New Log-linear Models"></a>New Log-linear Models</h2><p>大多数复杂性是由于模型中的非线性隐藏层引起的。模型结构如下：<img src="http://image.nysdy.com/20190506155713050638684.png" alt="20190506155713050638684.png"></p><h3 id="Continuous-Bag-of-Words-Model-CBOW"><a href="#Continuous-Bag-of-Words-Model-CBOW" class="headerlink" title="Continuous Bag-of-Words Model(CBOW)"></a>Continuous Bag-of-Words Model(CBOW)</h3><p>第一个提出的体系结构类似于前馈NNLM，其中去除了非线性隐藏层，并且所有单词（不仅仅是投影矩阵）共享投影层。 因此，所有单词都被投射到相同的位置（它们的向量被平均）。 将这个架构称为词袋模型，因为历史中的单词顺序不会影响投影。</p><p>模型的复杂度：Q = N × D + D × log_2(V )</p><h3 id="Continuous-Skip-gram-Model"><a href="#Continuous-Skip-gram-Model" class="headerlink" title="Continuous Skip-gram Model"></a>Continuous Skip-gram Model</h3><p>基于同一句子中的另一个单词最大化单词的分类。 更准确地说，使用每个当前单词作为具有连续投影层的对数线性分类器的输入，并预测当前单词之前和之后的特定范围内的单词。</p><p>模型的复杂度：Q = C × (D + D × log2(V ))，其中C是单词的最大距离。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>为了度量词向量的质量，我们定义了一个复杂的测试集，它包括了五种类型的语义问题。九个类型的句法问题。包括每个类别的两个样本集在上表展示；总之，共拥有8869个语义问题和10675个句法问题</p><p>作者通过：最大化精确度 ，模型体系结构的比较，模型的大规模并行训练来证明提出模型的运速度和精确的优势。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1301.3781.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，该篇论文的大篇幅都在讨论实验结果的分析，模型的部分比较简单，没有详细分析，本来是想读一下CBOW和skip-gram的原始论文，发现并没有想象中的那么大的用处。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="word2vec" scheme="http://yoursite.com/tags/word2vec/"/>
    
  </entry>
  
  <entry>
    <title>Shared Embedding Based Neural Networks for Knowledge Graph Completion阅读笔记</title>
    <link href="http://yoursite.com/post/Shared%20Embedding%20Based%20Neural%20Networks%20for%20Knowledge%20Graph%20Completion/"/>
    <id>http://yoursite.com/post/Shared Embedding Based Neural Networks for Knowledge Graph Completion/</id>
    <published>2019-04-19T06:52:38.000Z</published>
    <updated>2019-04-19T08:09:35.184Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://delivery.acm.org/10.1145/3280000/3271704/p247-guan.pdf?ip=59.64.129.243&amp;id=3271704&amp;acc=ACTIVE%20SERVICE&amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1555657159_db1582f1a6ea923a16011064e5cc7955" target="_blank" rel="noopener">原文下载链接</a>，知识图谱补全（KGC，Knowledge Graph Completion)是一种自动建立图谱内部知识关联的工作。目标是补全知识图谱中三元组的缺失部分。主要方法为基于张量（或者矩阵）和基于翻译两类。在本文中，作者提出了一种基于共享嵌入的神经网络的模型（SENN）来处理KGC。</p></blockquote><a id="more"></a><h2 id="Contribulation"><a href="#Contribulation" class="headerlink" title="Contribulation"></a>Contribulation</h2><ul><li>提出了SENN模型，该模型明确区分头实体、关系和为实体预测任务，并把它们整合到一个基于全连接神经网络框架中，该框架共享的实体和关系嵌入。</li><li>SENN提出了一个自适应全中损失机制，该方法可以很好的处理具有不同映射属性的三元组，并处理不同的预测任务。</li><li>由于关系预测通常比头尾实体预测具有更好的性能，我们把SENN应用到头尾实体预测，从而将SENN扩展到SENN+。</li></ul><h2 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h2><h3 id="Tensor-Matrix-Based-Methods"><a href="#Tensor-Matrix-Based-Methods" class="headerlink" title="Tensor/Matrix Based Methods"></a>Tensor/Matrix Based Methods</h3><p>RESCAL是一个典型的方法，该方法基于三向张量因子分解的方法。</p><p>目标函数为：<img src="http://image.nysdy.com/20190419155565817094503.png" alt="20190419155565817094503.png"></p><p>$M_r$是r的关系矩阵，大小为k x k。</p><p>ComlEx是最近提出的方法，该方法基于矩阵分解，并且它使用复数值来定义实体和关系的嵌入。</p><p>目标函数为：<img src="http://image.nysdy.com/20190419155565837140789.png" alt="20190419155565837140789.png"></p><p>Re(x)返回x的实部。</p><h3 id="Translation-Based-Methods"><a href="#Translation-Based-Methods" class="headerlink" title="Translation Based Methods"></a>Translation Based Methods</h3><p>代表模型为经典的TransE模型（这里不再赘述）</p><h3 id="Translation-Based-Methods-1"><a href="#Translation-Based-Methods-1" class="headerlink" title="Translation Based Methods"></a>Translation Based Methods</h3><p>ER-MLP使用多层感知器来捕获头实体，关系和尾实体之间的隐式交互。</p><p>目标函数为：<img src="http://image.nysdy.com/2019041915556586361053.png" alt="2019041915556586361053.png"></p><p>ProjE使用具有组合层和投影层的神经网络来对头尾实体预测建模。</p><h2 id="THE-SENN-METHOD"><a href="#THE-SENN-METHOD" class="headerlink" title="THE SENN METHOD"></a>THE SENN METHOD</h2><p>模型结构如图所示：<img src="http://image.nysdy.com/20190419155565880062506.png" alt="20190419155565880062506.png"></p><p>作者将框架划分为以下四个部分：</p><ol><li>三元组的批量预处理</li><li>知识图谱的Shared embeddings表示学习</li><li>独立的头尾实体及关系预测子模型训练与融合</li><li>联合损失函数构成</li></ol><p>整个KGC的流程可以描述如下：</p><ol><li>将训练数据中的完整三元组（知识图谱）划分批量后作为模型的输入</li><li>对于输入的三元组，分别训练得到实体（包括头尾实体）嵌入矩阵与关系嵌入矩阵（embeddings）</li><li>将头尾实体及关系embeddings分别输入到三个预测模型中（头实体预测（?, r, t），关系预测(h, ?, t)，尾实体预测(h, r, ?)）</li></ol><h3 id="The-Three-Substructures"><a href="#The-Three-Substructures" class="headerlink" title="The Three Substructures"></a>The Three Substructures</h3><p>预测子模型具有相似的结构如下图，模型输入关系向量与实体向量后，进入n层全连接层，得到预测向量，再经过一个sigmoid（或者softmax）层，输出预测标签向量。<img src="http://image.nysdy.com/20190419155565925349707.png" alt="20190419155565925349707.png"></p><p>头实体预测目标函数：<img src="http://image.nysdy.com/20190419155565929066802.png" alt="20190419155565929066802.png"></p><p>f(x)= max(0,x).</p><p>预测标签：<img src="http://image.nysdy.com/20190419155565936981620.png" alt="20190419155565936981620.png"></p><p>其它两种与此头实体类似。</p><h3 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h3><h4 id="The-General-Loss-Function"><a href="#The-General-Loss-Function" class="headerlink" title="The General Loss Function"></a>The General Loss Function</h4><p>模型目标标签向量表示为：<img src="http://image.nysdy.com/20190419155565949172586.png" alt="20190419155565949172586.png"></p><p>$I_h$是在训练集中给定r和t的所有有效头实体集。</p><p>三者的平滑向量表示为：<img src="http://image.nysdy.com/20190419155565967448577.png" alt="20190419155565967448577.png"></p><p>三个预测任务的损失函数为：<img src="http://image.nysdy.com/20190419155565972110097.png" alt="20190419155565972110097.png"></p><p>总损失函数为：<img src="http://image.nysdy.com/20190419155565974814392.png" alt="20190419155565974814392.png"></p><h4 id="The-Adaptively-Weighted-Loss-Mechanism"><a href="#The-Adaptively-Weighted-Loss-Mechanism" class="headerlink" title="The Adaptively Weighted Loss Mechanism."></a>The Adaptively Weighted Loss Mechanism.</h4><p>该方法的动机：</p><ul><li>在知识图谱中的三元组有4种类型：1-TO-1, 1-TO-M, M-TO-1 and M-TO-M。所以预测在训练集中具有的有效实体/关系越多，它就越不确定。所以作者将对应于头部实体预测，关系预测和尾部实体预测的损失的权重与有效实体的数量相关联。</li><li>因为关系预测比实体预测更加容易。所以作者加大对头尾实体的错误预测的惩罚。</li></ul><p>所以作者得到新的损失函数：<img src="http://image.nysdy.com/20190419155566013038361.png" alt="20190419155566013038361.png"></p><p>总损失函数变为：<img src="http://image.nysdy.com/20190419155566016395908.png" alt="20190419155566016395908.png"></p><h2 id="THE-SENN-METHOD-1"><a href="#THE-SENN-METHOD-1" class="headerlink" title="THE SENN+METHOD"></a>THE SENN+METHOD</h2><p>作者相信可以进一步利用关系预测的相当好的性能来辅助测试过程中的头部和尾部实体预测。</p><p>给定头部预测任务（？，r，t）并假设h是有效的头部实体。 如果我们采用SENN方法来预测h和t之间的关系，即执行关系预测任务（h，？，t），则关系r最有可能具有 预测标签高于其他关系，因此应排名高于其他关系。</p><p><img src="http://image.nysdy.com/20190419155566073220975.png" alt="20190419155566073220975.png"></p><p>其中Value（x，r）返回对应于关系r的向量x的条目; Rank（x，r）以降序返回对应于关系r的向量x的条目的等级。</p><p>最后SENN+种预测标签为：<img src="http://image.nysdy.com/20190419155566089424123.png" alt="20190419155566089424123.png"></p><p>其中<img src="http://image.nysdy.com/20190419155566090898589.png" alt="20190419155566090898589.png"></p><h2 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p><img src="http://image.nysdy.com/20190419155566095994824.png" alt="20190419155566095994824.png"></p><h3 id="Entity-Prediction"><a href="#Entity-Prediction" class="headerlink" title="Entity Prediction"></a>Entity Prediction</h3><p><img src="http://image.nysdy.com/20190419155566101939979.png" alt="20190419155566101939979.png"></p><p><img src="http://image.nysdy.com/20190419155566104394441.png" alt="20190419155566104394441.png"></p><h3 id="Relation-Prediction"><a href="#Relation-Prediction" class="headerlink" title="Relation Prediction"></a>Relation Prediction</h3><p><img src="http://image.nysdy.com/20190419155566106385514.png" alt="20190419155566106385514.png"></p><p>论文还进行了共享嵌入和自适应权重损失机制有效性的验证。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-%E9%9D%A2%E5%90%91%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8%E7%9A%84%E5%85%B1%E4%BA%AB%E5%B5%8C%E5%85%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-%E9%9D%A2%E5%90%91%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8%E7%9A%84%E5%85%B1%E4%BA%AB%E5%B5%8C%E5%85%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/3280000/3271704/p247-guan.pdf?ip=59.64.129.243&amp;amp;id=3271704&amp;amp;acc=ACTIVE%20SERVICE&amp;amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;amp;__acm__=1555657159_db1582f1a6ea923a16011064e5cc7955&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文下载链接&lt;/a&gt;，知识图谱补全（KGC，Knowledge Graph Completion)是一种自动建立图谱内部知识关联的工作。目标是补全知识图谱中三元组的缺失部分。主要方法为基于张量（或者矩阵）和基于翻译两类。在本文中，作者提出了一种基于共享嵌入的神经网络的模型（SENN）来处理KGC。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="知识图谱补全" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>《Bootstrapping Entity Alignment with Knowledge Graph Embedding》阅读笔记</title>
    <link href="http://yoursite.com/post/Bootstrapping%20Entity%20Alignment%20with%20Knowledge%20Graph%20Embedding/"/>
    <id>http://yoursite.com/post/Bootstrapping Entity Alignment with Knowledge Graph Embedding/</id>
    <published>2019-04-09T01:01:13.000Z</published>
    <updated>2019-04-09T02:58:37.713Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://www.ijcai.org/proceedings/2018/0611.pdf" target="_blank" rel="noopener">论文下载地址</a>，采用了bootstrapping方法来解决缺乏训练数据的过程，提出了截断均匀负采样来提高负样例对于目标函数的贡献，采用基于限制的目标函数来按需调整正负样例的得分。</p></blockquote><a id="more"></a><p>基于嵌入的实体对齐将不同的知识图谱（KG）表示为低维嵌入，并通过测量实体嵌入之间的相似性来查找实体对齐。其中，大量方法所面临的一个挑战是：缺乏足够的先前对齐作为标记的训练数据。</p><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul><li>作者把实体对齐建模为一个分类问题，其基于KG嵌入来寻求最大化所有标记和未标记的实体对齐可能性</li><li>对于面向对齐的KG嵌入，作者提出了一种基于限制的目标函数；为了对不太可能区分的负三元组进行抽样，作者提出了一种截断均匀的负抽样方法。</li><li>作者提出了一个自举过程（bootstrapping）来克服缺乏足够训练数据，通过标记可能的对齐并迭代地将其添加到训练数据中来更新面向对齐的嵌入。</li><li>作者在三个跨语言和两个大型数据集上评估了所提出的方法，表明所提出的方法明显优于三种最先进的实体对齐方法。</li></ul><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>最大似然准则指导选择实现最高对齐可能性的最佳θ</p><p><img src="http://image.nysdy.com/20190409155477420219240.png" alt="20190409155477420219240.png"></p><p>其中，L_x代表实体x的真实标签，1_[]是一个指示函数，表示给定命题的真值（0或1）。但是对于没有标签的实体，想要通过上述来得到theta就很困难。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="面向对齐的KG嵌入"><a href="#面向对齐的KG嵌入" class="headerlink" title="面向对齐的KG嵌入"></a>面向对齐的KG嵌入</h3><p>作者提出了一个目标函数：<img src="http://image.nysdy.com/2019040915547745103625.png" alt="2019040915547745103625.png"></p><p>该目标函数有两个期望的属性：</p><ul><li>预期正三元组得分较低，而负三元组得分较高。例如f(r)&lt;= r_1 并且 f(r’)&gt;=r_2，设置时r_2&gt;r_1,且r_1是一个小的正值。</li><li>仍然可以得到f(r’)-f(r)&gt;=r_2 - r_1，这表明所提出的目标函数仍然保留了基于边际排序损失的特征。</li></ul><h4 id="截断均匀负采样"><a href="#截断均匀负采样" class="headerlink" title="截断均匀负采样"></a>截断均匀负采样</h4><p>如果样例太容易区分，那么对整个的嵌入学习的贡献会很小。</p><p>所以，作者采用在嵌入空间中s最近的邻居作为候选集，剔除那些和实体x相似度过低的数据。</p><h3 id="引导对齐（Bootstrapping-Alignment）"><a href="#引导对齐（Bootstrapping-Alignment）" class="headerlink" title="引导对齐（Bootstrapping Alignment）"></a>引导对齐（Bootstrapping Alignment）</h3><p>作者迭代地将可能的对齐标记作为训练数据，并使用它来进一步改进实体嵌入和对齐。</p><h4 id="可能的对齐标签和编辑"><a href="#可能的对齐标签和编辑" class="headerlink" title="可能的对齐标签和编辑"></a>可能的对齐标签和编辑</h4><p>作者为了实现最大化对齐可能性并遵守一对一对齐约束，提出以下优化问题来标记第t次迭代：</p><p><img src="http://image.nysdy.com/20190409155477548037155.png" alt="20190409155477548037155.png"></p><p>Y’_x = {y|y ∈ Y’ and  π(y|x; Θ^(t)) &gt; γ3}代表标签x的候选集；ψ^(t)(·)是一个指示函数，只有当x在第t次迭代时标签为y时为1，其它情况为0。两个限制条件保证了一对一的标签。这时得到了一个新的标签对齐：<img src="http://image.nysdy.com/20190409155477586716499.png" alt="20190409155477586716499.png"></p><p>为了提高标签质量并满足一对一的对齐约束，在自举过程中，一旦被标记的实体可以在随后的标记中重新标记或变为未标记的实体。</p><p>当发生两个标签冲突时，我们通过计算下面的似然差异来确定保留哪个：<img src="http://image.nysdy.com/20190409155477607781047.png" alt="20190409155477607781047.png"></p><p>当该值大于0说明前者具有更大的对齐概率。</p><h4 id="从整体角度学习"><a href="#从整体角度学习" class="headerlink" title="从整体角度学习"></a>从整体角度学习</h4><p>为了获得标记和未标记实体的整理观察，作者定义了概率分布φx来描述所有x可能的概率分布。</p><p><img src="http://image.nysdy.com/20190409155477633963211.png" alt="20190409155477633963211.png"></p><p>由此，作者得到了最小化下面的似然函数来得到Θ：<img src="http://image.nysdy.com/20190409155477641976513.png" alt="20190409155477641976513.png"></p><p>因为，嵌入不仅应该捕获对齐可能性，还应该模拟KG的语义，所以作者最后定义联合目标函数：</p><p><img src="http://image.nysdy.com/20190409155477650541518.png" alt="20190409155477650541518.png"></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><ul><li>DBP15K [Sun et al., 2017]包含三个跨语言数据集，这些数据集是从DBpedia的多语言版本构建的。DBPZH-EN(Chinese to English), DBPJA-EN(Japanese to English) and DBPFR-EN(French to English)每个数据集包含15，000个参考实体对齐。</li><li>DWY100K包含从DBpedia，Wikidata和YAGO3中提取的两个大型数据集，由DBP-WD和DBP-YG表示。 每个数据集都有10万个参考实体对齐<img src="http://image.nysdy.com/20190409155477678270217.png" alt="20190409155477678270217.png"></li></ul><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>作者选取了三种最先进的基于嵌入的方法来实现实体对齐。</p><ul><li>MTransE [Chen et al., 2017]，选取了第四种变体（表现最佳）。</li><li>IPTransE[Zhu et al., 2017]是一个迭代方法</li><li>JAPE [Sun et al., 2017]结合了实体对齐的关系和属性嵌入</li><li>AlignE面向对齐的KG嵌入模型的实现，具有截断的均匀负采样和参数交换，它优化了公式（3），但是没有自举</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>表2中我们观察到AlignE明显优于MTransE，IPTransE和JAPE，因为它采用面向对齐的嵌入。而BootEA显着改善了AlignE的结果，表明了自举的良好性能是由于其能够准确地将可能的对齐标记为训练数据。</p><p><img src="http://image.nysdy.com/20190409155477712242929.png" alt="20190409155477712242929.png"></p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><h4 id="截断均匀负抽样的有效性"><a href="#截断均匀负抽样的有效性" class="headerlink" title="截断均匀负抽样的有效性"></a>截断均匀负抽样的有效性</h4><p><img src="http://image.nysdy.com/20190409155477794964299.png" alt="20190409155477794964299.png">从图中可以看出，与MTransE，IPTransE和JAPE相比，具有均匀负采样的AlignE仍然获得了优异的结果，并且随着采样离x更加接近，效果呈上升趋势。</p><h4 id="可能对齐的准确性"><a href="#可能对齐的准确性" class="headerlink" title="可能对齐的准确性"></a>可能对齐的准确性</h4><p><img src="http://image.nysdy.com/20190409155477815850691.png" alt="20190409155477815850691.png">可以看到以作者的标记方法S3表现最佳。这些结果证实作者的方法可以保证使用未标记数据的安全性。</p><h4 id="对先前对准比例的敏感性"><a href="#对先前对准比例的敏感性" class="headerlink" title="对先前对准比例的敏感性"></a>对先前对准比例的敏感性</h4><p><img src="http://image.nysdy.com/20190409155477832196109.png" alt="20190409155477832196109.png"></p><p>正如预期的那样，随着比例的增加，所有五个数据集的结果都变得更好，因为更多的先前对齐可以提供更多信息来对齐两个KG。</p><h4 id="F1-score-w-r-t-关系三元数的分布"><a href="#F1-score-w-r-t-关系三元数的分布" class="headerlink" title="F1-score w.r.t. 关系三元数的分布"></a>F1-score w.r.t. 关系三元数的分布</h4><p><img src="http://image.nysdy.com/20190409155477850975486.png" alt="20190409155477850975486.png"></p><p>BootEA在所有时间间隔都优于MTransE，IPTransE和JAPE，这再次证实了BootEA的有效性。而且BootEA可以在稀疏数据上取得有希望的结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ijcai.org/proceedings/2018/0611.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，采用了bootstrapping方法来解决缺乏训练数据的过程，提出了截断均匀负采样来提高负样例对于目标函数的贡献，采用基于限制的目标函数来按需调整正负样例的得分。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="知识图谱嵌入" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5/"/>
    
      <category term="实体对齐" scheme="http://yoursite.com/tags/%E5%AE%9E%E4%BD%93%E5%AF%B9%E9%BD%90/"/>
    
  </entry>
  
  <entry>
    <title>《Entity Alignment between Knowledge Graphs Using Attribute Embeddings》阅读笔记</title>
    <link href="http://yoursite.com/post/Entity%20Alignment%20between%20Knowledge%20Graphs%20Using%20Attribute%20Embeddings/"/>
    <id>http://yoursite.com/post/Entity Alignment between Knowledge Graphs Using Attribute Embeddings/</id>
    <published>2019-03-28T00:57:15.000Z</published>
    <updated>2019-04-01T01:32:23.185Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://people.eng.unimelb.edu.au/jianzhongq/papers/AAAI2019_EntityAlignment.pdf" target="_blank" rel="noopener">论文下载地址</a>，知识图之间的实体对齐的任务旨在在代表相同现实世界实体的两个知识图中找到实体。本文最主要就是提出了属性字符嵌入(attribute character embeddings)的方法。</p></blockquote><a id="more"></a><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>我们的模型利用知识图中存在的大量属性三元组(attribute triples)并生成属性字符嵌入。 属性字符嵌入(attribute character embeddings)通过基于实体的属性计算实体之间的相似性，将实体嵌入从两个知识图移位到同一空间中。<br>我们使用传递规则来进一步丰富实体的属性数量以增强属性字符嵌入。</p><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul><li>提出了两个KG之间实体对齐的框架，它由谓词对齐模块，嵌入学习模块和实体对齐模块组成。</li><li>提出了一种新颖的嵌入模型，它将实体嵌入与属性嵌入集成在一起，以便为两个KG学习统一的嵌入空间。</li><li>我们在三个真正的KG对上评估建议的模型。<br>结果表明，我们的模型在实体对齐任务上始终优于最先进的模型，hits@1超过50％。</li></ul><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="模型总览"><a href="#模型总览" class="headerlink" title="模型总览"></a>模型总览</h3><p>predicate alignment, embedding learning, and entity alignment</p><p><img src="http://image.nysdy.com/20190329155385087492759.png" alt="20190329155385087492759.png"></p><h3 id="Predicate-Alignment"><a href="#Predicate-Alignment" class="headerlink" title="Predicate Alignment"></a>Predicate Alignment</h3><p>谓词对齐模块通过使用统一的命名方案重命名两个KG的谓词来合并两个KG，以便为关系嵌入提供统一的向量空间。dbp:bornIn vs. yago:wasBornIn 统一命名为 :bornIn。</p><p>为了找到部分匹配的谓词，作者计算谓词URI的最后部分的编辑距离（例如，bornIn与wasBornIn）并将0.95设置为相似性阈值。</p><h2 id="Embedding-Learning"><a href="#Embedding-Learning" class="headerlink" title="Embedding Learning"></a>Embedding Learning</h2><h3 id="Structure-Embedding"><a href="#Structure-Embedding" class="headerlink" title="Structure Embedding"></a>Structure Embedding</h3><p>作者采用TransE来学习对于实体的结构嵌入。与TransE不同的是，模型希望更关注已对齐的三元组，也就是包含对齐谓词的三元组。模型通过添加权重来实现这一目的。Structure embedding的目标函数如下：</p><p><img src="http://image.nysdy.com/2019040115540798067483.png" alt="2019040115540798067483.png"></p><p>count(r)是关系r出现的数量。</p><h3 id="Attribute-Character-Embedding"><a href="#Attribute-Character-Embedding" class="headerlink" title="Attribute Character Embedding"></a>Attribute Character Embedding</h3><p>对于属性字符嵌入，也参考TransE的思想，将谓词r解释为从头部实体h到属性a的转换。但是，相同的属性a可以在两个KG中以不同的形式出现，例如50.9989对50.9988888889作为实体的纬度; “Barack Obama”与“Barack Hussein Obama”作为人名等。因此，本文提出使用组合函数对属性值进行编码，并将属性三元组中每个元素的关系定义为h +r≈fa（a）。 这里，fa（a）是组合函数，a是属性值a = {c1，c2，c3，…，ct}的字符序列。 组合函数将属性值编码为单个向量，并将类似的属性值映射到类似的向量表示。 作者定义了三个组成函数如下。</p><h4 id="Sum-compositional-function-SUM"><a href="#Sum-compositional-function-SUM" class="headerlink" title="Sum compositional function (SUM)"></a>Sum compositional function (SUM)</h4><p>存在问题：包含相同字符不同顺序的属性值会有相同的向量表示</p><p><img src="http://image.nysdy.com/20190401155408045744772.png" alt="20190401155408045744772.png"></p><h4 id="LSTM-based-compositional-function-LSTM"><a href="#LSTM-based-compositional-function-LSTM" class="headerlink" title="LSTM-based compositional function (LSTM)."></a>LSTM-based compositional function (LSTM).</h4><p><img src="http://image.nysdy.com/20190401155408065416786.png" alt="20190401155408065416786.png"></p><h4 id="N-gram-based-compositional-function-N-gram"><a href="#N-gram-based-compositional-function-N-gram" class="headerlink" title="N-gram-based compositional function (N-gram)"></a>N-gram-based compositional function (N-gram)</h4><p><img src="http://image.nysdy.com/20190401155408070480904.png" alt="20190401155408070480904.png"></p><p>最后attribute character embedding目标函数：<img src="http://image.nysdy.com/20190401155408075852436.png" alt="20190401155408075852436.png"></p><h3 id="Joint-Learning-of-Structure-Embedding-and-Attribute-Character-Embedding"><a href="#Joint-Learning-of-Structure-Embedding-and-Attribute-Character-Embedding" class="headerlink" title="Joint Learning of Structure Embedding and Attribute Character Embedding"></a>Joint Learning of Structure Embedding and Attribute Character Embedding</h3><p>作者使用属性字符嵌入通过最小化以下目标函数将结构嵌入移动到相同的向量空间：</p><p><img src="http://image.nysdy.com/20190401155408233583946.png" alt="20190401155408233583946.png"></p><p>本文整体损失函数：</p><p><img src="http://image.nysdy.com/20190401155408096945378.png" alt="20190401155408096945378.png"></p><h3 id="Entity-Alignment"><a href="#Entity-Alignment" class="headerlink" title="Entity Alignment"></a>Entity Alignment</h3><p>在经过上述训练过程之后，来自不同KG的相似的实体将会有相似的向量表示，因此可通过</p><p><img src="http://image.nysdy.com/2019040115540811204332.png" alt="2019040115540811204332.png"></p><p>获得潜在实体对齐对<h_1, h_map="">。此外，模型设定相似度阈值来过滤潜在实体对齐对，得到最终的对齐结果。</h_1,></p><h3 id="Triple-Enrichment-via-Transitivity-Rule"><a href="#Triple-Enrichment-via-Transitivity-Rule" class="headerlink" title="Triple Enrichment via Transitivity Rule"></a>Triple Enrichment via Transitivity Rule</h3><p>作者利用一阶逻辑传递关系来丰富三元组。即：存在<h_1,t_1,t>和<t, r_2,t_2="">则可以推理出h_1+ (r_1.r_2) ≈ t_2</t,></h_1,t_1,t></p><h2 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h2><p>本文从 DBpedia (DBP)、LinkedGeoData (LGD)、Geonames (GEO) 和 YAGO 四个 KG 中抽取构建了三个数据集，分别是DBP-LGD、DBP-GEO和DBP-YAGO。具体的数据统计如下：</p><p><img src="http://image.nysdy.com/20190401155408149973345.png" alt="20190401155408149973345.png"></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Entity-Alignment-Results"><a href="#Entity-Alignment-Results" class="headerlink" title="Entity Alignment Results"></a>Entity Alignment Results</h3><p>本文对比了三个相关的模型，分别是 TransE、MTransE 和 JAPE。试验结果表明，本文提出的模型在实体对齐任务上取得了全面的较大的提升，在三种组合函数中，N-gram函数的优势较为明显。此外，基于传递规则的三元组丰富模型对结果也有一定的提升。具体结果如下<img src="http://image.nysdy.com/20190401155408163227980.png" alt="20190401155408163227980.png"></p><h3 id="Rule-based-Entity-Alignment-Results"><a href="#Rule-based-Entity-Alignment-Results" class="headerlink" title="Rule-based Entity Alignment Results"></a>Rule-based Entity Alignment Results</h3><p>为了进一步衡量 attribute character embedding 捕获实体间相似信息的能力，本文设计了基于规则的实体对齐模型。本实验对比了三种不同的模型：以label的字符串相似度作为基础模型；针对数据集特点，在基础模型的基础之上增加了坐标属性，以此作为第二个模型；第三个模型是把本文提出的模型作为附加模型，与基础模型相结合。具体结果如下：</p><p><img src="http://image.nysdy.com/20190401155408175594725.png" alt="20190401155408175594725.png"></p><h3 id="KG-Completion-Results"><a href="#KG-Completion-Results" class="headerlink" title="KG Completion Results"></a>KG Completion Results</h3><p>本文还在KG补全任务上验证了模型的有效性。模型主要测试了链接预测和三元组分类两个标准任务，在这两个任务中，模型也取得了不错的效果。具体结果如下：</p><p><img src="http://image.nysdy.com/20190401155408179146202.png" alt="20190401155408179146202.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://people.eng.unimelb.edu.au/jianzhongq/papers/AAAI2019_EntityAlignment.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，知识图之间的实体对齐的任务旨在在代表相同现实世界实体的两个知识图中找到实体。本文最主要就是提出了属性字符嵌入(attribute character embeddings)的方法。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="知识图谱嵌入" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5/"/>
    
  </entry>
  
  <entry>
    <title>《RelNN A Deep Neural Model for Relational Learning》阅读笔记</title>
    <link href="http://yoursite.com/post/RelNN%20A%20Deep%20Neural%20Model%20for%20Relational%20Learning/"/>
    <id>http://yoursite.com/post/RelNN A Deep Neural Model for Relational Learning/</id>
    <published>2019-03-25T01:34:57.000Z</published>
    <updated>2019-04-01T02:34:41.280Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/pdf/1712.02831.pdf" target="_blank" rel="noopener">论文下载地址</a>，这篇文章相当于结合了统计学习和深度神经网络。里面有些公式没有理解，应该是有许多先前论文需要阅读。但是本篇论文扩展了思路如何结合统计学和深度学习，并且基于其余数据来预测一个类中对象的一个属性，想法也比较好。</p></blockquote><a id="more"></a><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>作者主要集中于基于其余数据来预测一个类中对象的一个属性。</p><h2 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h2><p>当类中每个对象的属性依赖于不同数量的其他对象的属性和关系时，此问题具有挑战性。 在StarAI社区中，此问题称为聚合（aggregation）。</p><h2 id="Relational-Logistic-Regression-and-Markov-Logic-Networks"><a href="#Relational-Logistic-Regression-and-Markov-Logic-Networks" class="headerlink" title="Relational Logistic Regression and Markov Logic Networks"></a>Relational Logistic Regression and Markov Logic Networks</h2><p>StarAI模型旨在模拟对象之间关系的概率。 </p><h3 id="Relational-logistic-regression-RLR-Kazemi-et-al-2014"><a href="#Relational-logistic-regression-RLR-Kazemi-et-al-2014" class="headerlink" title="Relational logistic regression (RLR) (Kazemi et al. 2014)"></a>Relational logistic regression (RLR) (Kazemi et al. 2014)</h3><p>定义的概率公式如下：</p><p><img src="http://image.nysdy.com/20190327155364804947436.png" alt="20190327155364804947436.png"></p><p>上面定义的RLR模型仅适用于布尔值或多值父项。作者采用的是连续的原子（continuous atoms）（Fatemi, Kazemi, and Poole (2016)）</p><h3 id="Relational-Neural-Networks"><a href="#Relational-Neural-Networks" class="headerlink" title="Relational Neural Networks"></a>Relational Neural Networks</h3><p>作者通过设计神经网络中线性层（LL），激活层（AL）和误差层（EL）的关系对应物，对具有分层架构的RLR / MLN模型进行编码。</p><p>关系神经网络（RelNN）是包含作为图形彼此连接的若干RLL和RAL的结构。</p><p><img src="http://image.nysdy.com/20190327155364863172988.png" alt="20190327155364863172988.png"></p><h2 id="Motivations-for-hidden-layers"><a href="#Motivations-for-hidden-layers" class="headerlink" title="Motivations for hidden layers"></a>Motivations for hidden layers</h2><ul><li>使喜欢看动作电影的人数增加时，男性的概率变为[0, 1]重的任何数值，不至于直接变为0或者1。</li><li>因此，隐藏层通过使模型能够学习通用规则并相应地对对象进行分类，然后以不同方式处理不同类别的对象，从而提高了建模能力。</li><li>使用RLR表示不同类型的现有显式聚合器，然而有些情况需要使用2个RLLs和2个RALs</li></ul><h2 id="Learning-latent-properties-directly"><a href="#Learning-latent-properties-directly" class="headerlink" title="Learning latent properties directly"></a>Learning latent properties directly</h2><p>对象可能包含无法使用常规规则指定的潜在属性，但可以在训练期间直接从数据中学习。</p><p><img src="http://image.nysdy.com/20190327155364936417890.png" alt="20190327155364936417890.png"></p><p>考虑图2中的模型，让Latent（m）成为电影的数字潜在属性，其值将在训练期间学习。</p><h2 id="From-ConvNet-Primitives-to-RelNNs"><a href="#From-ConvNet-Primitives-to-RelNNs" class="headerlink" title="From ConvNet Primitives to RelNNs"></a>From ConvNet Primitives to RelNNs</h2><p>我们解释为什么RelNN也可以被视为ConvNets的一个实例。</p><p>ConvNets的输入矩阵中的单元（例如，图像像素）具有空间相关性和空间冗余：彼此更接近的单元比更远的单元更依赖。 例如，如果M表示图像的输入通道，则M [i，j]和M [i + 1，j + 1]之间的依赖性可能远大于M [i，j]和M [i，j+20]之间的依赖性。</p><p>对于关系数据，输入矩阵中的依赖关系（关系）是不同的：同一行或列中的单元（即同一对象的关系）具有比不同行和列中的单元更高的依赖性（即不同对象的关系）。 因此，为了使ConvNets适应关系数据，我们需要矢量形状的过滤器，这些过滤器对行和列交换是不变的，并且更好地捕获关系依赖性和可交换性假设。</p><p><img src="http://image.nysdy.com/2019032715536511162060.png" alt="2019032715536511162060.png"></p><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><h3 id="Movielens-1M-dataset-Harper-and-Konstan-2015"><a href="#Movielens-1M-dataset-Harper-and-Konstan-2015" class="headerlink" title="Movielens 1M dataset (Harper and Konstan 2015)"></a>Movielens 1M dataset (Harper and Konstan 2015)</h3><p>第一个数据集是Movielens 1M dataset (Harper and Konstan 2015)，忽略了实际的评级，只考虑电影是否被评级，只考虑动作和戏剧类型。</p><h3 id="PAKDD15"><a href="#PAKDD15" class="headerlink" title="PAKDD15"></a>PAKDD15</h3><p><a href="https://knowledgepit.fedcsis.org/contest/view.php?id=107" target="_blank" rel="noopener">获取地址</a></p><h3 id="all-Chinese-and-Mexican-restaurants-in-Yelp-dataset-challenge"><a href="#all-Chinese-and-Mexican-restaurants-in-Yelp-dataset-challenge" class="headerlink" title="all Chinese and Mexican restaurants in Yelp dataset challenge"></a>all Chinese and Mexican restaurants in Yelp dataset challenge</h3><p><a href="https://www.yelp.com/dataset_challenge" target="_blank" rel="noopener">获取地址</a></p><h2 id="Empirical-Results"><a href="#Empirical-Results" class="headerlink" title="Empirical Results"></a>Empirical Results</h2><p>作者提出了三个问题来进行实验：</p><h3 id="Q1：RelNN的性能与其他众所周知的关系学习算法相比如何？"><a href="#Q1：RelNN的性能与其他众所周知的关系学习算法相比如何？" class="headerlink" title="Q1：RelNN的性能与其他众所周知的关系学习算法相比如何？"></a>Q1：RelNN的性能与其他众所周知的关系学习算法相比如何？</h3><p><img src="http://image.nysdy.com/20190327155365126319780.png" alt="20190327155365126319780.png"></p><h3 id="Q2：基于数字和规则的潜在属性如何影响RelNN的性能"><a href="#Q2：基于数字和规则的潜在属性如何影响RelNN的性能" class="headerlink" title="Q2：基于数字和规则的潜在属性如何影响RelNN的性能?"></a>Q2：基于数字和规则的潜在属性如何影响RelNN的性能?</h3><p>更改了RelNN中隐藏图层和数字潜在属性的数量，以查看它们如何影响性能。</p><p><img src="http://image.nysdy.com/20190327155365168099042.png" alt="20190327155365168099042.png"></p><p>请注意，添加图层只会添加一定数量的参数，但添加k个数字潜在属性会增加k * |Δm|参数。</p><h3 id="Q3：RelNN如何推断出看不见的案例并解决指向的规模大小问题-（Poole-et-al-2014）"><a href="#Q3：RelNN如何推断出看不见的案例并解决指向的规模大小问题-（Poole-et-al-2014）" class="headerlink" title="Q3：RelNN如何推断出看不见的案例并解决指向的规模大小问题 （Poole et al.2014）?"></a>Q3：RelNN如何推断出看不见的案例并解决指向的规模大小问题 （Poole et al.2014）?</h3><p>作者实施了两个实验：</p><ul><li>我们在大量数据中训练一个RelNN，并在一小数据上进行测试：该实验可以看作每个模型受冷启动问题的严重程度</li><li>然后我们在一小数据上训练一个RelNN并在一大数据上进行测试：可以看作这些模型对更大群体的推断</li></ul><p><img src="http://image.nysdy.com/20190327155365190971381.png" alt="20190327155365190971381.png"></p><h2 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h2><p>作者将从数据中自动学习这些结构的问题留作未来的工作。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1712.02831.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，这篇文章相当于结合了统计学习和深度神经网络。里面有些公式没有理解，应该是有许多先前论文需要阅读。但是本篇论文扩展了思路如何结合统计学和深度学习，并且基于其余数据来预测一个类中对象的一个属性，想法也比较好。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="关系抽取" scheme="http://yoursite.com/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"/>
    
      <category term="统计学习" scheme="http://yoursite.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《Interaction Embeddings for Prediction and Explanation》阅读笔记</title>
    <link href="http://yoursite.com/post/Interaction%20Embeddings%20for%20Prediction%20and%20Explanation/"/>
    <id>http://yoursite.com/post/Interaction Embeddings for Prediction and Explanation/</id>
    <published>2019-03-21T06:07:37.000Z</published>
    <updated>2019-03-25T01:59:25.370Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://www.zora.uzh.ch/id/eprint/162876/1/interaction-embeddings-prediction_merlin_version.pdf" target="_blank" rel="noopener">论文下载地址</a>，此论文主要提出了实体和关系的交互作用对于知识图谱嵌入的影响，和提出了新的嵌入评估方案 - 搜索预测解释。</p></blockquote><a id="more"></a><h2 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h2><ul><li>提出了CrossE，一种通过学习一个交互矩阵来给实体和关系的交互建模的新型知识图谱嵌入。</li><li>我们使用三个基准数据集评估CrossE与链接预测任务上的各种其他KGE的比较，并显示CrossE在具有适度参数大小的复杂且更具挑战性的数据集上实现最先进的结果。</li><li>我们提出了一种新的嵌入评估方案 - 搜索预测解释，并表明CrossE能够生成比其他方法更可靠的解释。 这表明交互嵌入更能在不同的三元组环境中捕捉实体和关系之间的相似性。</li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>给定知识图谱和一个要预测的三元组的头实体和关系，在预测尾实体的过程中，头实体和关系之间是有交叉交互的crossover interaction, 即关系决定了在预测的过程中哪些头实体的信息是有用的，而对预测有用的头实体的信息又决定了采用什么逻辑去推理出尾实体，文中通过一个模拟的知识图谱进行了说明如下图所示：</p><p><img src="http://image.nysdy.com/20190321155314902217434.png" alt="20190321155314902217434.png"></p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>论文中在这部分对KGE（Knowledge graph embedding）进行了分类总结：</p><ul><li>KGEs with general embeddings</li><li>KGEs with multiple embeddings.</li><li>KGEs that utilize extra information.</li></ul><p>这部分总结中对大量的方法进行描述，可以作为背景知识进行阅读。</p><h2 id="CrossE模型"><a href="#CrossE模型" class="headerlink" title="CrossE模型"></a>CrossE模型</h2><p>基于对头实体和关系之间交叉交互的观察，本文提出了一个新的知识图谱表示学习模型CrossE. CrossE除了学习实体和关系的向量表示，同时还学习了一个交互矩阵C，C与关系相关，并且用于生成实体和关系经过交互之后的向量表示，所以在CrossE中实体和关系不仅仅有通用向量表示，同时还有很多交互向量表示。CrossE核心想法如下图：<img src="http://image.nysdy.com/20190321155314970714298.png" alt="20190321155314970714298.png"></p><p>目标函数粉四步生成：</p><ol><li>Interaction Embedding for Entities：根据头实体向量和交互矩阵（以关系确定的）来确定头实体的交互表示。</li><li>Interaction Embedding for Relations：根据头实体的交互表示和关系作用生成关系的交互表示</li><li>Combination Operator：将头实体的交互表示和关系的交互表示相结合，并进行非线性处理（tanh）</li><li>Similarity Operator：计算结合后表示和尾实体表示之间的相似度。</li></ol><p>最后分数函数：</p><p><img src="http://image.nysdy.com/20190321155315073712112.png" alt="20190321155315073712112.png"></p><p>损失函数：（这里就是一个交叉熵函数，但是写的有问题f(x)项应该在括号外）<img src="http://image.nysdy.com/20190321155315081421205.png" alt="20190321155315081421205.png"></p><h2 id="对于预测的解释"><a href="#对于预测的解释" class="headerlink" title="对于预测的解释"></a>对于预测的解释</h2><p>这部分作者描述了如何生成预测三元组的解释，并介绍了基于嵌入的路径搜索算法，主要步骤如下：</p><ol><li>Search for similar relations：修剪掉不合理路径</li><li>Search for paths between h and t：作者定义了6种路径（班汉一个或两个关系）</li><li>Search similar entities：捕获实体之间的相似性方面越有能力，就越有可能存在（hs，r，ts）</li><li>: Search for similar structures as supports：我们只将知识图中至少有一个支持的路径视为解释。</li></ol><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><img src="http://image.nysdy.com/20190321155315142112584.png" alt="20190321155315142112584.png"></p><h3 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h3><p><img src="/Users/dy/Library/Application Support/typora-user-images/image-20190321145750608.png" alt="image-20190321145750608"></p><p><img src="http://image.nysdy.com/20190321155315147862891.png" alt="20190321155315147862891.png"></p><p>从实验结果中我们可以看出，CrossE实现了较好的链接预测结果。我们去除CrossE中的头实体和关系的交叉交互，构造了模型 CrossES，CrossE 和 CrossES 的比较说明了交叉交互的有效性。</p><h3 id="生成解释"><a href="#生成解释" class="headerlink" title="生成解释"></a>生成解释</h3><p>我们提出了一种基于相似结构通过知识图谱的表示学习结果生成预测结果解释的方法，并提出了两种衡量解释结果的指标，AvgSupport和Recall。Recall是指模型能给出解释的预测结果的占比，其介于0和1之间且值越大越好；AvgSupport是模型能给出解释的预测结果的平均support个数，AvgSupport是一个大于0的数且越大越好。可解释的评估结果如下：</p><p><img src="http://image.nysdy.com/2019032115531515625385.png" alt="2019032115531515625385.png"></p><p>链接预测和可解释的实验从两个不同的方面评估了知识图谱表示学习的效果，同时也说明了链接预测的准确性和可解释性没有必然联系，链接预测效果好的模型并不一定能够更好地提供解释，反之亦然。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-interaction-embeddings-for-prediction-and-explanation/" target="_blank" rel="noopener">http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-interaction-embeddings-for-prediction-and-explanation/</a></li></ul><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zora.uzh.ch/id/eprint/162876/1/interaction-embeddings-prediction_merlin_version.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;，此论文主要提出了实体和关系的交互作用对于知识图谱嵌入的影响，和提出了新的嵌入评估方案 - 搜索预测解释。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="知识图谱嵌入" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5/"/>
    
      <category term="知识图谱推理" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《Differentiable Learning of Logical Rules for Knowledge Base Reasoning》阅读笔记</title>
    <link href="http://yoursite.com/post/Differentiable%20Learning%20of%20Logical%20Rules%20for%20Knowledge%20Base%20Reasoning/"/>
    <id>http://yoursite.com/post/Differentiable Learning of Logical Rules for Knowledge Base Reasoning/</id>
    <published>2019-03-05T07:34:05.000Z</published>
    <updated>2019-03-10T13:25:50.136Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>论文<a href="http://papers.nips.cc/paper/6826-differentiable-learning-of-logical-rules-for-knowledge-base-reasoning.pdf" target="_blank" rel="noopener">下载地址</a>，本文研究用于于知识图谱推理的学习概率一阶逻辑规则的问题，提出了Neural Logic Programming（Neural-LP）框架，它结合了端到端可微分模型中一阶逻辑规则的参数和结构学习。为了在可微分的框架中同时学习参数和结构，作者设计了一个具有注意机制和记忆的神经控制器系统，以学习顺序组成TensorLog使用的原始可微操作。作者采用的注意机制是作为逻辑规则的置信度并且有寓意含义的。</p></blockquote><a id="more"></a><p>下图展示了一个使用逻辑规则进行知识图谱推理的例子</p><p><img src="https://i.loli.net/2019/03/05/5c7dc90edacd1.jpg" alt=""></p><p>使用概率逻辑的优点是通过为逻辑规则配备概率，可以更好地模拟统计复杂和噪声数据。</p><p>statistical relational learning（统计关系学习）：学习关系规则的集合</p><p>==inductive logic programming（归纳逻辑规划）：==当学习涉及提出新的逻辑规则时。（这应该和我正在做的方向是相关的，都是带有归纳性质的，有新的东西产生）。</p><h1 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h1><h2 id="Knowledge-base-reasoning"><a href="#Knowledge-base-reasoning" class="headerlink" title="Knowledge base reasoning"></a>Knowledge base reasoning</h2><p>为了推理知识库，对于每个查询我们都有兴趣学习以下形式的加权链式逻辑规则，类似于<strong>==随机逻辑程序==</strong>：</p><p><img src="https://i.loli.net/2019/03/05/5c7dcd6e1a5ac.jpg" alt=""></p><p>其中$\alpha$是和规则有关的置信度，R是知识库中的关系，query(Y,X) 表示一个三元组，query 表示一个关系。</p><h2 id="TensorLog-for-KB-reasoning"><a href="#TensorLog-for-KB-reasoning" class="headerlink" title="TensorLog for KB reasoning"></a>TensorLog for KB reasoning</h2><p>将实体转换成one-hot变量；并用一个矩阵$M_R$表示关系，该矩阵只在（i，j）处为1，i、j为第i、j个实体。</p><p>结合两个操作，逻辑规则推理$R(Y,X) \gets P(Y,X) \bigwedge Q(Z,X)$可以被表示为：$M_P \cdot M_P \cdot v_x \doteq s$，向量s中为1的位置就是Y的答案。</p><p>对于一条查询，所有的逻辑规则的右边部分被表示为以下形式：</p><p><img src="https://i.loli.net/2019/03/05/5c7dda071bcef.jpg" alt=""></p><p>其中，l表示所有的可能规则的个数，$\alpha_l$是规则l的置信度，$\beta_l$是某特定关系里的有序关系列表，所以在inference时，给定实体$v_x​$，实体y的score等于向量s中的对应y的位置的值。对于推理，给定实体x，实体y的score等于向量s中的对应y的位置的值。</p><p><img src="https://i.loli.net/2019/03/10/5c85104e2a53b.jpg" alt=""></p><p>所以总结本文关心的优化问题如下：</p><p><img src="https://i.loli.net/2019/03/05/5c7e1568d9ec7.jpg" alt=""></p><h2 id="Learning-the-logical-rules"><a href="#Learning-the-logical-rules" class="headerlink" title="Learning the logical rules"></a>Learning the logical rules</h2><p>在上式的优化问题中，算法需要学习的部分分为两个：一个是规则的结构，即一个规则是由哪些条件组合而成的；另一个是规则的置信度。由于每一条规则的置信度都是依赖于具体的规则形式，而规则结构的组成也是一个离散化的过程，因此上式整体是不可微的。因此作者对前面的式子做了以下更改：<img src="https://i.loli.net/2019/03/05/5c7e160404436.jpg" alt=""></p><p>对比与式（2）：主要交换了连乘和累加的计算顺序，对预一个关系的相关的规则，为每个关系在每个步骤都学习了一个权重，即上式的 $a_t^k$。</p><p>由于上式固定了每个规则的长度都为 T，这显然是不合适的。为了能够学习到变长的规则，Neural LP中设计了记忆向量 $u_t$,表示每个步骤输出的答案—每个实体作为答案的概率分布，还设计了两个注意力向量：一个为记忆注意力向量 $b_t$ ——表示在步骤 t 时对于之前每个步骤的注意力；一个为算子注意力向量 $a_t$ ——表示在步骤 t 时对于每个关系算子的注意力。每个步骤的输出由下面三个式子生成：<img src="https://i.loli.net/2019/03/05/5c7e18ac09662.jpg" alt=""></p><p>其中$b_t$和$a_t$由以下公式通过RNN获得：</p><p><img src="https://i.loli.net/2019/03/05/5c7e1a015f0ac.jpg" alt=""></p><p>推理机的整体框架是：</p><p><img src="https://i.loli.net/2019/03/05/5c7e1aec1aea9.jpg" alt=""></p><p>其中memory存的就是每步的推理结果（实体），最后的输出（例如$u_{T+1}$，目标就是最大化 $logv_y^Tu$，加log是因为非线性能让效果变好。</p><p>整个算法如下：<img src="https://i.loli.net/2019/03/05/5c7e1c0d5cf32.jpg" alt=""></p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="（1）-两个标准数据集上的统计关系学习相关的实验"><a href="#（1）-两个标准数据集上的统计关系学习相关的实验" class="headerlink" title="（1） 两个标准数据集上的统计关系学习相关的实验"></a>（1） 两个标准数据集上的统计关系学习相关的实验</h2><ul><li>Unified Medical Language System (UMLS)：The entities are biomedical concepts (e.g. disease, antibiotic) and relations are like treats and diagnoses.</li><li>Kinship：contains kinship relationships among members of the Alyawarra tribe from Central Australia [</li></ul><p><img src="https://i.loli.net/2019/03/05/5c7e2270289d0.jpg" alt=""></p><h2 id="（2）-在-16-16-的网格上的路径寻找的实验"><a href="#（2）-在-16-16-的网格上的路径寻找的实验" class="headerlink" title="（2） 在$16*16$的网格上的路径寻找的实验"></a>（2） 在$16*16$的网格上的路径寻找的实验</h2><p><img src="https://i.loli.net/2019/03/05/5c7e235b430cb.jpg" alt=""></p><h2 id="（3）-知识库补全实验"><a href="#（3）-知识库补全实验" class="headerlink" title="（3） 知识库补全实验"></a>（3） 知识库补全实验</h2><p>实验所用数据集信息：</p><p>FB15KSelected：这是通过从FB15K中去除近似重复和反向关系而构造的</p><p><img src="https://i.loli.net/2019/03/05/5c7e2378e1c64.jpg" alt=""></p><p>实验结果：<img src="https://i.loli.net/2019/03/05/5c7e23c43db48.jpg" alt=""></p><p>为了证明Neural LP的归纳推理的能力，本文还特别设计了一个实验，在训练数据集中去掉所有涉及测试集中包含的实体的三元组，然后训练并预测，得到结果如下：<img src="https://i.loli.net/2019/03/05/5c7e23ebbca69.jpg" alt=""></p><h2 id="（4）-知识库问答的实验"><a href="#（4）-知识库问答的实验" class="headerlink" title="（4） 知识库问答的实验"></a>（4） 知识库问答的实验</h2><p><img src="https://i.loli.net/2019/03/05/5c7e24aa6a427.jpg" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1><p>本文提出了一个可微的规则学习模型，并强调了知识库中的规则应该是实体无关的，对于我目前在做的方向，本体论也是与实体无关的，这种规则学习有一定的借鉴性，但是好像所区别。这个规则推理也可以看成某些关系之间的包含关系3.1中举的HasOfficeInCity(New York,Uber) and CityInCountry(USA,New York)的例子，可以看作是2对于1有包含关系。并且可以看到本篇论文中，作者设计了丰富的实验。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://toutiao.io/posts/wrxf4z/preview" target="_blank" rel="noopener">https://toutiao.io/posts/wrxf4z/preview</a></li><li><a href="https://zhuanlan.zhihu.com/p/46024825" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46024825</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;论文&lt;a href=&quot;http://papers.nips.cc/paper/6826-differentiable-learning-of-logical-rules-for-knowledge-base-reasoning.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下载地址&lt;/a&gt;，本文研究用于于知识图谱推理的学习概率一阶逻辑规则的问题，提出了Neural Logic Programming（Neural-LP）框架，它结合了端到端可微分模型中一阶逻辑规则的参数和结构学习。为了在可微分的框架中同时学习参数和结构，作者设计了一个具有注意机制和记忆的神经控制器系统，以学习顺序组成TensorLog使用的原始可微操作。作者采用的注意机制是作为逻辑规则的置信度并且有寓意含义的。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="知识图谱推理" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86/"/>
    
      <category term="规则学习" scheme="http://yoursite.com/tags/%E8%A7%84%E5%88%99%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《OK Google, What Is Your Ontology? Or/ Exploring Freebase Classification to Understand Google’s Knowledge Graph？》阅读笔记</title>
    <link href="http://yoursite.com/post/OK%20Google,%20What%20Is%20Your%20Ontology?%20Or/%20Exploring%20Freebase%20Classification%20to%20Understand%20Google%E2%80%99s%20Knowledge%20Graph%EF%BC%9F/"/>
    <id>http://yoursite.com/post/OK Google, What Is Your Ontology? Or/ Exploring Freebase Classification to Understand Google’s Knowledge Graph？/</id>
    <published>2019-03-03T13:29:07.000Z</published>
    <updated>2019-03-10T13:52:42.099Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本论文详细阐述Freebase中的数据格式，并进行了重构。通过考虑整体架构的三个部分：Freebase类型系统及其缺乏继承和依赖于不兼容性，允许表示值的不确定性的实现，以及合并和拆分对象的实现。来对本体进行阐述。<a href="https://arxiv.org/pdf/1805.03885.pdf" target="_blank" rel="noopener">论文下载地址</a></p></blockquote><a id="more"></a><p>这篇论文重构了Freebase数据转储来理解谷歌语义搜索特征背后的本体。论文将会探索Freebase本体如何由许多力量塑造的，这些力量也通过深入研究本体论和一个小的相关性研究来形成分类系统。这些发现将会提供知识图谱专有黑盒的一瞥。</p><blockquote><p>The structures found in the Freebase/Knowledge Graph ontology will be analyzed in light of the findings on classification systems in a key text by Bowker and Star (2000) [5].</p></blockquote><h1 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a>术语定义</h1><p><img src="https://i.loli.net/2019/03/03/5c7b61c1bd122.jpg" alt=""></p><h3 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h3><p>Freebase对象是一个全局唯一的标识符，它是Freebase中世界上某种东西的表示。</p><h3 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h3><p>Freebase类型用来表达类的概念。</p><h3 id="Property"><a href="#Property" class="headerlink" title="Property"></a>Property</h3><p>Freebase属性是描述对象如何链接到其他值或对象的关系。</p><h3 id="Property-Detail"><a href="#Property-Detail" class="headerlink" title="Property Detail"></a>Property Detail</h3><p>属性详细信息指的是可以通过属性链接的对象或值的约束。</p><h3 id="RDF-triple"><a href="#RDF-triple" class="headerlink" title="RDF triple"></a>RDF triple</h3><p>资源描述格式（RDF）是用于“三元组”（或N = 3元组）格式的数据表示的规范[17]。</p><h3 id="Ontology"><a href="#Ontology" class="headerlink" title="Ontology"></a>Ontology</h3><p>对于本文，Freebase本体是类型，属性和属性详细信息的正式结构和描述，用于指定对象如何相互关联。</p><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>在本文中，架构指的是可以在本体中找到的一般模式和关系。</p><p><strong>==本体是否允许类（或Freebase用语中的类型）之间的继承？ 是否有与属性相关的默认值？ 如何处理“零”或空值？ 这些类型的问题不一定关注本体（飞机，火车或汽车）中具体表达的内容，而是关于本体表达方式的更多问题应该通过检查架构来解决。==</strong></p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><p>作者把数据进行切分：按照RDF中三元组的谓语进行分类，例如：<img src="https://i.loli.net/2019/03/03/5c7bc58f2052d.jpg" alt=""></p><h1 id="Freebase-Ontology-and-Classification"><a href="#Freebase-Ontology-and-Classification" class="headerlink" title="Freebase Ontology and Classification"></a>Freebase Ontology and Classification</h1><blockquote><p> As Bowker and Star note, “Information infrastructure is a tricky thing to analyze…the easier they are to use, the harder they are to see.” [5]. What does the system make sense of? What is left out? What is privileged and by extension what is ignored by Google?</p></blockquote><p>虽然Freebase本体可能不会立即看起来像一个分类系统，但类型（类）和属性的结构是一个基于对各种事物进行分类的系统。</p><p>作为对世界事物表征进行排序和分类的系统，将根据Bowker和Star的分类结果讨论Freebase本体。他们将对亚里士多德和原型分类（Aristotelian and prototype classification）进行了区分。</p><p>亚里士多德的分类“按照一组二元特征进行操作，被分类的物体呈现或不呈现”，而原型分类则认为“在我们心目中对于椅子是什么的广泛描述; 我们用隐喻和类比来扩展这张图片“</p><h2 id="5-1-Freebase’s-Type-System"><a href="#5-1-Freebase’s-Type-System" class="headerlink" title="5.1. Freebase’s Type System"></a>5.1. Freebase’s Type System</h2><p>不兼容性的概念出现在Freebase系统中，用于表示对象如何具有某些类型，而这些类型必须将其排除在其他类型之外。</p><p>没有继承（not implement inheritance）：上述不兼容性在确保数据不表达可能在Google KP中提供的令人尴尬，有害或不正确的陈述方面发挥了足够强大的作用。</p><p>缺乏继承也可能是一种允许实体具有更大灵活性的特征。这里作者举了一个狗为电影演员的例子。</p><h2 id="5-2-Has-Value-or-Has-No-Value"><a href="#5-2-Has-Value-or-Has-No-Value" class="headerlink" title="5.2. Has Value or Has No Value?"></a>5.2. Has Value or Has No Value?</h2><p>三元组如何表达估计值，不确定值或空值？实际处理时用“Has Value” (HV) and “Has No Value” (HNV)来分别表达不确定值和空值。</p><p>以这种方式表达未知数和空值的有趣实现可能表明Freebase / KG最初并不是为了支持这种不确定性而建立的。Google的数据编码某些不确定性的概念并未向最终用户公开，尽管它肯定以这种独特的方式实现。</p><h2 id="5-3-Dealing-with-Doppelgangers-and-Chimeras"><a href="#5-3-Dealing-with-Doppelgangers-and-Chimeras" class="headerlink" title="5.3. Dealing with Doppelgangers and Chimeras"></a>5.3. Dealing with Doppelgangers and Chimeras</h2><p>涉及Freebase如何处理“合并”重复对象（doppelgangers）和“拆分”混合对象（嵌合体）。 </p><blockquote><p>the property “/dataworld/gardening hint/replaced by” is used to implement merges be- tween various objects (e.g. by saying “/m/xyz123 - Replaced By - /m/abc123”).</p></blockquote><h1 id="A-Small-Correlational-Study"><a href="#A-Small-Correlational-Study" class="headerlink" title="A Small Correlational Study"></a>A Small Correlational Study</h1><p>主要探索这个问题：域的本体的复杂性（人物，电影等领域的类型，属性等）与表达与本体相关的事实（“知识库”）的三元组数量之间是否存在关联？</p><p>对于本研究，通过考虑与域相关的属性详细信息量（多少描述，约束等）来实现“复杂性”和“成熟度”。</p><p>对于89个域中的每一个，获得了关于每个域的本体的以下统计：</p><ul><li>==<strong>域中的类型和属性数</strong>==</li><li>==<strong>每种类型和属性的描述数</strong>==</li><li>==<strong>每种类型和属性的属性详细信息数==</strong></li></ul><p><strong>通过获取域中每种类型和属性的平均描述数和属性详细信息来计算简单的复杂性分数。 所有域的RDF三元组计数与此复杂性得分之间的Pearson相关系数与0.2824呈正相关，简单线性回归的斜率为78,424.08（见图6）。 当排除异常音乐切片时，相关性和斜率分别变为0.6680和33,899.53。 虽然需要进一步的工作来探索这个研究问题，但这个小的相关性研究为进一步的实验提供了一些有希望的初步结果</strong></p><h1 id="discussion"><a href="#discussion" class="headerlink" title="discussion"></a>discussion</h1><p>考虑整体架构的三个部分：Freebase类型系统及其缺乏继承和依赖于不兼容性，允许表示值的不确定性的实现，以及合并和拆分对象的实现。此外，还进行了一项小型相关研究，以检验基于Bowker和Star推动的预感的假设。在很大程度上，分类系统中的许多特征也可以在Freebase的本体和体系结构中找到。</p><p>本文具体而言，探讨了支持整个交付流程的基础结构（本体和体系结构），而不是Freebase / KG中表示的特定事实。</p><h1 id="conclusion"><a href="#conclusion" class="headerlink" title="conclusion"></a>conclusion</h1><p> 应通过探索Freebase本体和体系结构的其他方面以及对Freebase进行更全面的实验分析来进行进一步的研究。 </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本论文详细阐述Freebase中的数据格式，并进行了重构。通过考虑整体架构的三个部分：Freebase类型系统及其缺乏继承和依赖于不兼容性，允许表示值的不确定性的实现，以及合并和拆分对象的实现。来对本体进行阐述。&lt;a href=&quot;https://arxiv.org/pdf/1805.03885.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文下载地址&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
      <category term="Ontology" scheme="http://yoursite.com/tags/Ontology/"/>
    
      <category term="freebase" scheme="http://yoursite.com/tags/freebase/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式</title>
    <link href="http://yoursite.com/post/Regular%20expression/"/>
    <id>http://yoursite.com/post/Regular expression/</id>
    <published>2019-02-18T11:57:01.000Z</published>
    <updated>2019-02-18T12:02:06.028Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文参考了一些链接，记录了一些常用正则表达式的详细使用方法。</p></blockquote><a id="more"></a><p>在自然语言处理中，很多时候我们都需要从文本或字符串中抽取出想要的信息，并进一步做语义理解或其它处理。在本文中，作者由基础到高级介绍了很多正则表达式，这些表达式或规则在很多编程语言中都是通用的。</p><p><a href="https://regex101.com/r/cO8lqs/11" target="_blank" rel="noopener">书写正则表达式网站</a></p><p>正则表达式（regex 或 regexp）对于从文本中抽取信息极其有用，它一般会搜索匹配特定模式的语句，而这种模式及具体的 ASCII 序列或 Unicode 字符。从解析/替代字符串、预处理数据到网页爬取，正则表达式的应用范围非常广。</p><p>其中一个比较有意思的地方是，只要我们学会了正则表达式的语句，我们几乎可以将其应用于多有的编程语言，包括 JavaScript、Python、Ruby 和 Java 等。只不过对于各编程语言所支持的最高级特征与语法有细微的区别。</p><p>下面我们可以具体讨论一些案例与解释。</p><h1 id="基本语句"><a href="#基本语句" class="headerlink" title="基本语句"></a><strong>基本语句</strong></h1><h2 id="锚点：-和"><a href="#锚点：-和" class="headerlink" title="锚点：^ 和 $"></a><strong>锚点：^ 和 $</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">^The        匹配任何以“The”开头的字符串 </span><br><span class="line">end$        匹配以“end”为结尾的字符串</span><br><span class="line">^The end$   抽取匹配从“The”开始到“end”结束的字符串</span><br><span class="line">roar        匹配任何带有文本“roar”的字符串</span><br></pre></td></tr></table></figure><h2 id="数量符：-、-、？和"><a href="#数量符：-、-、？和" class="headerlink" title="数量符：*、+、？和 {}**"></a>数量符：*、+、？和 {}**</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">abc*        匹配在“ab”后面跟着零个或多个“c”的字符串 </span><br><span class="line">abc+        匹配在“ab”后面跟着一个或多个“c”的字符串</span><br><span class="line">abc?        匹配在“ab”后面跟着零个或一个“c”的字符串</span><br><span class="line">abc&#123;2&#125;      匹配在“ab”后面跟着两个“c”的字符串</span><br><span class="line">abc&#123;2,&#125;     匹配在“ab”后面跟着两个或更多“c”的字符串</span><br><span class="line">abc&#123;2,5&#125;    匹配在“ab”后面跟着2到5个“c”的字符串</span><br><span class="line">a(bc)*      匹配在“a”后面跟着零个或更多“bc”序列的字符串</span><br><span class="line">a(bc)&#123;2,5&#125;  匹配在“a”后面跟着2到5个“bc”序列的字符串</span><br></pre></td></tr></table></figure><h2 id="或运算符：-、"><a href="#或运算符：-、" class="headerlink" title="或运算符：| 、 []"></a><strong>或运算符：| 、 []</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a(b|c)     匹配在“a”后面跟着“b”或“c”的字符串 </span><br><span class="line">a[bc]      匹配在“a”后面跟着“b”或“c”的字符串</span><br></pre></td></tr></table></figure><h2 id="字符类：-d、-w、-s-和"><a href="#字符类：-d、-w、-s-和" class="headerlink" title="字符类：\d、\w、\s 和 .**"></a>字符类：\d、\w、\s 和 .**</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">\d         匹配数字型的单个字符 </span><br><span class="line">\w         匹配单个词字（字母加下划线） </span><br><span class="line">\s         匹配单个空格字符（包括制表符和换行符） </span><br><span class="line">.          匹配任意字符</span><br></pre></td></tr></table></figure><p>使用「.」运算符需要非常小心，因为常见类或排除型字符类都要更快与精确。\d、\w 和\s 同样有它们各自的排除型字符类，即\D、\W 和\S。例如\D 将执行与\d 完全相反的匹配方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\D         匹配单个非数字型的字符</span><br></pre></td></tr></table></figure><p>为了正确地匹配，我们必须使用转义符反斜杠「\」定义我们需要匹配的符号「^.[$()|*+?{\」，因为我们可能认为这些符号在原文本中有特殊的含义。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\$\d       匹配在单个数字前有符号“$”的字符串 -&gt; Try it! (https://regex101.com/r/cO8lqs/9)</span><br></pre></td></tr></table></figure><p>注意我们同样能匹配 non-printable 字符，例如 Tab 符「\t」、换行符「\n」和回车符「\r」</p><h2 id="Flags"><a href="#Flags" class="headerlink" title="Flags"></a><strong>Flags</strong></h2><p>我们已经了解如何构建正则表达式，但仍然遗漏了一个非常基础的概念：flags。</p><p>正则表达式通常以/abc/这种形式出现，其中搜索模式由两个反斜杠「/」分离。而在模式的结尾，我们通常可以指定以下 flag 配置或它们的组合：</p><ul><li>g（global）在第一次完成匹配后并不会返回结果，它会继续搜索剩下的文本。</li><li>m（multi line）允许使用^和$匹配一行的开始和结尾，而不是整个序列。</li><li>i（insensitive）令整个表达式不区分大小写（例如/aBc/i 将匹配 AbC）。</li></ul><h1 id="中级语句"><a href="#中级语句" class="headerlink" title="中级语句"></a><strong>中级语句</strong></h1><h2 id="分组和捕获："><a href="#分组和捕获：" class="headerlink" title="分组和捕获：()"></a><strong>分组和捕获：()</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a(bc)           圆括弧会创建一个捕获性分组，它会捕获匹配项“bc” </span><br><span class="line">a(?:bc)*        使用 “?:” 会使捕获分组失效，只需要匹配前面的“a” </span><br><span class="line">a(?&lt;foo&gt;bc)     使用 “?&lt;foo&gt;” 会为分组配置一个名称</span><br></pre></td></tr></table></figure><p>捕获性圆括号 () 和非捕获性圆括弧 (?:) 对于从字符串或数据中抽取信息非常重要，我们可以使用 Python 等不同的编程语言实现这一功能。从多个分组中捕获的多个匹配项将以经典的数组形式展示：我们可以使用匹配结果的索引访问它们的值。</p><p>如果需要为分组添加名称（使用 (?<foo>…)），我们就能如字典那样使用匹配结果检索分组的值，其中字典的键为分组的名称。</foo></p><h2 id="方括弧表达式："><a href="#方括弧表达式：" class="headerlink" title="方括弧表达式：[]"></a><strong>方括弧表达式：[]</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[abc]            匹配带有一个“a”、“ab”或“ac”的字符串 -&gt; 与 a|b|c 一样 </span><br><span class="line">[a-c]            匹配带有一个“a”、“ab”或“ac”的字符串 -&gt; 与 a|b|c 一样</span><br><span class="line">[a-fA-F0-9]      匹配一个代表16进制数字的字符串，不区分大小写 </span><br><span class="line">[0-9]%           匹配在%符号前面带有0到9这几个字符的字符串</span><br><span class="line">[^a-zA-Z]        匹配不带a到z或A到Z的字符串，其中^为否定表达式</span><br></pre></td></tr></table></figure><p>记住在方括弧内，所有特殊字符（包括反斜杠\）都会失去它们应有的意义。</p><h2 id="Greedy-和-Lazy-匹配"><a href="#Greedy-和-Lazy-匹配" class="headerlink" title="==Greedy 和 Lazy 匹配=="></a><strong>==Greedy 和 Lazy 匹配==</strong></h2><p>数量符（* + {}）是一种贪心运算符，所以它们会遍历给定的文本，并尽可能匹配。例如，&lt;.+&gt; 可以匹配文本「This is a <div> simple div</div> test」中的「<div>simple div</div>」。为了仅捕获 div 标签，我们需要使用「？」令贪心搜索变得 Lazy 一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;.+?&gt;            一次或多次匹配 “&lt;” 和 “&gt;” 里面的任何字符，可按需扩展</span><br></pre></td></tr></table></figure><p>注意更好的解决方案应该需要避免使用「.」，这有利于实现更严格的正则表达式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;[^&lt;&gt;]+&gt;         一次或多次匹配 “&lt;” 和 “&gt;” 里面的任何字符，除去 “&lt;” 或 “&gt;” 字符</span><br></pre></td></tr></table></figure><p><strong>高级语句</strong></p><p><strong>边界符：\b 和 \B</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\babc\b          执行整词匹配搜索</span><br></pre></td></tr></table></figure><p>\b 如插入符号那样表示一个锚点（它与$和^相同）来匹配位置，其中一边是一个单词符号（如\w），另一边不是单词符号（例如它可能是字符串的起始点或空格符号）。</p><p>它同样能表达相反的非单词边界「\B」，它会匹配「\b」不会匹配的位置，如果我们希望找到被单词字符环绕的搜索模式，就可以使用它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Babc\B          只要是被单词字符环绕的模式就会匹配</span><br></pre></td></tr></table></figure><h2 id="前向匹配和后向匹配：-和-lt"><a href="#前向匹配和后向匹配：-和-lt" class="headerlink" title="前向匹配和后向匹配：(?=) 和 (?&lt;=)"></a><strong>前向匹配和后向匹配：(?=) 和 (?&lt;=)</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d(?=r)       只有在后面跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分 </span><br><span class="line">(?&lt;=r)d      只有在前面跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分</span><br></pre></td></tr></table></figure><p>我们同样能使用否定运算子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d(?!r)       只有在后面不跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分 </span><br><span class="line">(?&lt;!r)d      只有在前面不跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分</span><br></pre></td></tr></table></figure><p><strong>结语</strong></p><p>正如上文所示，正则表达式的应用领域非常广，很可能各位读者在开发的过程中已经遇到了它，下面是正则表达式常用的领域：</p><ul><li>数据验证，例如检查时间字符串是否符合格式；</li><li>数据抓取，以特定顺序抓取包含特定文本或内容的网页；</li><li>数据包装，将数据从某种原格式转换为另外一种格式；</li><li>字符串解析，例如捕获所拥有 URL 的 GET 参数，或捕获一组圆括弧内的文本；</li><li>字符串替代，将字符串中的某个字符替换为其它字符。</li></ul><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650749657&amp;idx=4&amp;sn=da4852cb0c4919316d801fe19a64901d&amp;chksm=871afea7b06d77b1bda42ac134c5dddad5af24647f62a5a8e7bdcef4499f40fd4c97045a6f3d&amp;mpshare=1&amp;scene=23&amp;srcid=1009dbNFxJJahsQK6NGw4wS3%23rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650749657&amp;idx=4&amp;sn=da4852cb0c4919316d801fe19a64901d&amp;chksm=871afea7b06d77b1bda42ac134c5dddad5af24647f62a5a8e7bdcef4499f40fd4c97045a6f3d&amp;mpshare=1&amp;scene=23&amp;srcid=1009dbNFxJJahsQK6NGw4wS3%23rd</a></p><h1 id="python正则表达式的使用"><a href="#python正则表达式的使用" class="headerlink" title="python正则表达式的使用"></a>python<a href="https://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html" target="_blank" rel="noopener">正则表达式的使用</a></h1><h1 id="正则表达式match和search的区别"><a href="#正则表达式match和search的区别" class="headerlink" title="正则表达式match和search的区别"></a><a href="https://segmentfault.com/a/1190000006736033" target="_blank" rel="noopener">正则表达式match和search的区别</a></h1>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文参考了一些链接，记录了一些常用正则表达式的详细使用方法。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="爬虫" scheme="http://yoursite.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="正则表达式" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>2019年计划</title>
    <link href="http://yoursite.com/post/2019-plans/"/>
    <id>http://yoursite.com/post/2019-plans/</id>
    <published>2019-02-09T02:14:09.000Z</published>
    <updated>2019-02-09T02:16:25.285Z</updated>
    
    <content type="html"><![CDATA[<h3 id="读个博"><a href="#读个博" class="headerlink" title="读个博"></a>读个博</h3><h3 id="吉他可以弹唱几首流行歌曲"><a href="#吉他可以弹唱几首流行歌曲" class="headerlink" title="吉他可以弹唱几首流行歌曲"></a>吉他可以弹唱几首流行歌曲</h3><p>假期报个班，请老师指点一下</p><h3 id="精读50篇论文"><a href="#精读50篇论文" class="headerlink" title="精读50篇论文"></a>精读50篇论文</h3><p>平均下来，每周都需要读一篇，每一篇都要勾划，发博客。</p><h3 id="发2篇paper"><a href="#发2篇paper" class="headerlink" title="发2篇paper"></a>发2篇paper</h3><p>上半年积累知识，做实验，暑假开始写</p><h3 id="考托福过90"><a href="#考托福过90" class="headerlink" title="考托福过90"></a>考托福过90</h3><p>上半年背单词等</p><h3 id="买个微单学个拍照"><a href="#买个微单学个拍照" class="headerlink" title="买个微单学个拍照"></a>买个微单学个拍照</h3><p>不急，现在没钱，下半年入手一个吧</p><h3 id="自己出门旅行一次"><a href="#自己出门旅行一次" class="headerlink" title="自己出门旅行一次"></a>自己出门旅行一次</h3><p>嗯，要是论文写完就去吧！目前计划去山东，顺便看一下我二姑。5天左右的旅行吧！</p><h3 id="学习滑板"><a href="#学习滑板" class="headerlink" title="学习滑板"></a>学习滑板</h3><h3 id="开始健身"><a href="#开始健身" class="headerlink" title="开始健身"></a>开始健身</h3><p>每周去三次健身房</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;读个博&quot;&gt;&lt;a href=&quot;#读个博&quot; class=&quot;headerlink&quot; title=&quot;读个博&quot;&gt;&lt;/a&gt;读个博&lt;/h3&gt;&lt;h3 id=&quot;吉他可以弹唱几首流行歌曲&quot;&gt;&lt;a href=&quot;#吉他可以弹唱几首流行歌曲&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="annual plans" scheme="http://yoursite.com/categories/annual-plans/"/>
    
    
      <category term="plan" scheme="http://yoursite.com/tags/plan/"/>
    
  </entry>
  
  <entry>
    <title>《An Automatic Knowledge Graph Construction System for K-12 Education》阅读笔记</title>
    <link href="http://yoursite.com/post/An%20Automatic%20Knowledge%20Graph%20Construction%20System%20for%20K-12%20Education/"/>
    <id>http://yoursite.com/post/An Automatic Knowledge Graph Construction System for K-12 Education/</id>
    <published>2019-01-19T02:32:57.000Z</published>
    <updated>2019-01-19T02:34:06.787Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://delivery.acm.org/10.1145/3240000/3231698/a40-chen.pdf?ip=59.64.129.211&amp;id=3231698&amp;acc=NO%20RULES&amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1547779677_7b4dce90b008fa6300a47916eeb139d9" target="_blank" rel="noopener">论文原址</a>。本篇文章主要提出了一个自动化构建数学领域知识图谱的系统，主要应用的事NER和数据挖掘技术，其中NER主要是抽取数学概念，概念间的关系是作者自己构建的（例如先修关系）。对于数据集，作者主要从the Chinese curriculum standards of mathematics上提取的概念实体，从自己的SLP平台上，通过对学生表现来提取关系（把这部分作为数据挖掘）。<strong>本篇文章实际上可以作为构建特定领域的知识图谱的一个参考。</strong></p></blockquote><a id="more"></a><h3 id="challenges"><a href="#challenges" class="headerlink" title="challenges"></a>challenges</h3><ul><li>the desired educational concept entities are more abstract than real world entities like PERSON, ORGANIZATION, LOCATION</li><li>the desired relations are more cognitive and implicit, so cannot be derived from the literal meanings of text like generic knowledge graphs</li></ul><h3 id="contributions"><a href="#contributions" class="headerlink" title="contributions"></a>contributions</h3><ul><li>a novel but practical system</li><li>entity recognition (NER) &amp; association rule mining algorithms</li><li>demonstrate an exemplary case with constructing a knowledge graph for the subject of mathematics</li></ul><h2 id="SYSTEM-OVERVIEW"><a href="#SYSTEM-OVERVIEW" class="headerlink" title="SYSTEM OVERVIEW"></a>SYSTEM OVERVIEW</h2><p><img src="https://i.loli.net/2019/01/19/5c428c37364b4.jpg" alt=""></p><ul><li>Educational Concept Extraction Module:</li><li>Implicit Relation Identification Module</li></ul><h2 id="CONCEPT-EXTRACTION"><a href="#CONCEPT-EXTRACTION" class="headerlink" title="CONCEPT EXTRACTION"></a>CONCEPT EXTRACTION</h2><ul><li><p>线性链式CRF模型</p><p><img src="https://i.loli.net/2019/01/18/5c4141ca00be1.jpg" alt=""></p></li><li><p>标签预测</p><p><img src="https://i.loli.net/2019/01/18/5c4141ed6ac27.jpg" alt=""></p></li></ul><h2 id="RELATION-IDENTIFICATION"><a href="#RELATION-IDENTIFICATION" class="headerlink" title="RELATION IDENTIFICATION"></a>RELATION IDENTIFICATION</h2><h3 id="两种方法"><a href="#两种方法" class="headerlink" title="两种方法"></a>两种方法</h3><ul><li>support</li><li>confidence</li></ul><blockquote><p>From the perspective of prerequisite relation, if concept si is a prerequisite of concept sj, learners who do not master sivery likely do not master sj, and learners who master sjmost likely master si. </p><p><img src="https://i.loli.net/2019/01/18/5c41425aafc99.jpg" alt=""></p></blockquote><h2 id="EXEMPLARY-CASE-AND-SYSTEM-EVALUATION"><a href="#EXEMPLARY-CASE-AND-SYSTEM-EVALUATION" class="headerlink" title="EXEMPLARY CASE AND SYSTEM EVALUATION"></a>EXEMPLARY CASE AND SYSTEM EVALUATION</h2><h3 id="Concept-Extraction"><a href="#Concept-Extraction" class="headerlink" title="Concept Extraction"></a>Concept Extraction</h3><h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p>the Chinese curriculum standards of mathematics published by the ministry of education as the main data source</p><h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><ul><li>adopt precision, recall and F1- score </li><li>The ground truth is manually labeled by two domain experts.</li></ul><h3 id="Relation-Identification"><a href="#Relation-Identification" class="headerlink" title="Relation Identification"></a>Relation Identification</h3><h4 id="Dataset-1"><a href="#Dataset-1" class="headerlink" title="Dataset"></a>Dataset</h4><p> students’ performance data collected by our SLP platform.</p><h4 id="Evaluation-1"><a href="#Evaluation-1" class="headerlink" title="Evaluation"></a>Evaluation</h4><p>The ground truth of the prerequisite relations between selected 9 concepts are annotated manually by two domain experts.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/3240000/3231698/a40-chen.pdf?ip=59.64.129.211&amp;amp;id=3231698&amp;amp;acc=NO%20RULES&amp;amp;key=BF85BBA5741FDC6E%2E66A15327C2E204FC%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;amp;__acm__=1547779677_7b4dce90b008fa6300a47916eeb139d9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文原址&lt;/a&gt;。本篇文章主要提出了一个自动化构建数学领域知识图谱的系统，主要应用的事NER和数据挖掘技术，其中NER主要是抽取数学概念，概念间的关系是作者自己构建的（例如先修关系）。对于数据集，作者主要从the Chinese curriculum standards of mathematics上提取的概念实体，从自己的SLP平台上，通过对学生表现来提取关系（把这部分作为数据挖掘）。&lt;strong&gt;本篇文章实际上可以作为构建特定领域的知识图谱的一个参考。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NER" scheme="http://yoursite.com/tags/NER/"/>
    
      <category term="知识图谱" scheme="http://yoursite.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
  </entry>
  
  <entry>
    <title>《RECURRENT NEURAL NETWORK REGULARIZATION》阅读笔记</title>
    <link href="http://yoursite.com/post/RECURRENT%20NEURAL%20NETWORK%20REGULARIZATION/"/>
    <id>http://yoursite.com/post/RECURRENT NEURAL NETWORK REGULARIZATION/</id>
    <published>2019-01-07T00:56:13.000Z</published>
    <updated>2019-01-07T01:37:11.397Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://arxiv.org/abs/1409.2329" target="_blank" rel="noopener">论文链接</a>。这篇论文提出了LSTM的dropout策略来防止过拟合，即只在非循环链接处采取dropout。在BasicLSTMCell的接口就是依据这篇论文实现的。</p></blockquote><h2 id="文章整体架构和重点"><a href="#文章整体架构和重点" class="headerlink" title="文章整体架构和重点"></a>文章整体架构和重点</h2><p><img src="https://i.loli.net/2019/01/07/5c32ad34c99e0.jpg" alt=""></p><h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><ul><li>present a simple regularization technique</li></ul><h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><ul><li><p>dropout Srivastava(2013)，对于前向反馈网络最有力的正则化方法并不能很好的应用在RNNs上。这导致RNNs规模都很小，因为太大会过拟合。</p></li><li><p>Bayer et al. (2013)指出了卷积dropout不能在RNNs上很好工作的原因是循环会放大噪音。</p></li></ul><h2 id="model"><a href="#model" class="headerlink" title="model"></a>model</h2><h3 id="仿射变换（affine-transform）"><a href="#仿射变换（affine-transform）" class="headerlink" title="仿射变换（affine transform）"></a>仿射变换（affine transform）</h3><p>关于仿射变换：线性变换加上平移，盗个知乎上的图（<a href="https://www.zhihu.com/question/20666664" target="_blank" rel="noopener">原文链接</a>）</p><p><img src="https://i.loli.net/2019/01/07/5c32a7c05c698.jpg" alt=""></p><h3 id="模型主体"><a href="#模型主体" class="headerlink" title="模型主体"></a>模型主体</h3><p>采用的是Graves et al. (2013)<img src="https://i.loli.net/2019/01/07/5c32aaae11c93.jpg" alt=""></p><h3 id="dropout策略"><a href="#dropout策略" class="headerlink" title="dropout策略"></a>dropout策略</h3><blockquote><p>The main contribution of this paper is a recipe for applying dropout to LSTMs in a way that success- fully reduces overfitting. The main idea is to apply the dropout operator only to the non-recurrent connections.</p></blockquote><p><img src="https://i.loli.net/2019/01/07/5c32aaf4084fc.jpg" alt=""></p><p>观察公式，实际上就是通过在层间传递中应用dropout。如下图中虚线所示。</p><p><img src="https://i.loli.net/2019/01/07/5c32a99676abf.jpg" alt=""></p><p>从上图中也可以看到，该dropout的次数只和网络深度有关（数值为网络深度+1）。</p><h3 id="experiments"><a href="#experiments" class="headerlink" title="experiments"></a>experiments</h3><p>实验部分作者做了4部分实验来证明自己采用的方法有效，分别为language modeling, speech recognition, machine translation, image caption generation。这部分没什么需要解释了，感兴趣可以自己看一下实验。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1409.2329&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文链接&lt;/a&gt;。这篇论文提出了LSTM的dropout策略来防止过拟合，即只在非循环链接处采取drop
      
    
    </summary>
    
      <category term="神经网络" scheme="http://yoursite.com/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Understanding LSTM Networks</title>
    <link href="http://yoursite.com/post/Understanding%20LSTM%20Networks/"/>
    <id>http://yoursite.com/post/Understanding LSTM Networks/</id>
    <published>2019-01-06T06:44:13.000Z</published>
    <updated>2019-01-06T06:47:07.555Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">原文链接</a>。这篇文章很好很细的一步一步的分解讲解了LSTM，之前看过一篇翻译的博客，现在自己翻译一遍，感觉对LSTM的认识加深了许多，虽然还是对LSTM中存有一些问题，比如为什么用tanh，sigmoid，为什不采用其他的？，但是看过之后至少对LSTM没有那么畏惧，不觉得过于复杂了。</p></blockquote><a id="more"></a><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><h2 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h2><p><img src="https://i.loli.net/2019/01/06/5c31826c20c5f.jpg" alt=""></p><p>循环允许信息从一个网络传入下一个。</p><p><img src="https://i.loli.net/2019/01/06/5c3189b3b43e8.jpg" alt=""></p><p>一个循环网络可以被认为是相同网络的多个复制，每一个网络都将信息传递给后继者。这种类似链的性质表明，递归神经网络与序列和列表密切相关。</p><h2 id="The-Problem-of-Long-Term-Dependencies"><a href="#The-Problem-of-Long-Term-Dependencies" class="headerlink" title="The Problem of Long-Term Dependencies"></a>The Problem of Long-Term Dependencies</h2><p>RNN的一个吸引力是他们可能能够将先前信息连接到当前任务。</p><ul><li><p>有时，我们只需要查看最近的信息来执行当前任务。例如：</p><blockquote><p>If we are trying to predict the last word in “the clouds are in the <em>sky</em>,” we don’t need any further context – it’s pretty obvious the next word is going to be sky.</p></blockquote><p> 在这种情况下，如果相关信息与待预测地方之间的差距很小，RNN可以学习使用过去的信息。</p></li><li><p>但是，对于一些情况，我们需要更多的上下文信息。</p><blockquote><p>Consider trying to predict the last word in the text “I grew up in France… I speak fluent <em>French</em>.”</p></blockquote><p>这时，相关信息与需要变得非常大的点之间的差距完全有可能。不幸的是，随着差距的扩大，RNN无法学会连接信息。</p><blockquote><p>The problem was explored in depth by <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="noopener">Hochreiter (1991) [German]</a> and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>, who found some pretty fundamental reasons why it might be difficult.</p></blockquote></li></ul><h2 id="LSTM-Networks"><a href="#LSTM-Networks" class="headerlink" title="LSTM Networks"></a>LSTM Networks</h2><blockquote><p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p></blockquote><p>标准RNNs的重复模块只有一个简单的结构，比如tanh层。</p><p><img src="https://i.loli.net/2019/01/06/5c31942fa0852.jpg" alt=""></p><p>LSTMs也有像这种链式结构，但是它的重复模块具有不同的结构。 有四个，而不是一个神经网络层，以一种非常特殊的方式进行交互。</p><p><img src="https://i.loli.net/2019/01/06/5c3195013e06a.jpg" alt=""></p><p>基本符号如下：</p><p><img src="https://i.loli.net/2019/01/06/5c319541ec43b.jpg" alt=""></p><p>在上图中，每一行都携带一个完整的向量，从一个节点的输出到其他节点的输入。 粉色圆圈表示逐点运算，如矢量加法，而黄色框表示神经网络层。 行合并表示连接，而行分叉表示其内容被复制，副本将转移到不同的位置。</p><h2 id="The-Core-Idea-Behind-LSTMs"><a href="#The-Core-Idea-Behind-LSTMs" class="headerlink" title="The Core Idea Behind LSTMs"></a>The Core Idea Behind LSTMs</h2><p><strong>LSTM的关键是单元状态</strong>，水平线贯穿图的顶部。</p><p>单元状态有点像传送带。 它直接沿着整个链运行，只有一些微小的线性相互作用。 信息很容易沿着它不变地流动。</p><p><img src="https://i.loli.net/2019/01/06/5c31965a2ea97.jpg" alt=""></p><p>LSTM确实能够移除或添加信息到细胞状态，由称为门的结构精心调节。</p><p>门是一种可选择通过信息的方式。 它们由Sigmoid神经网络层和逐点乘法运算组成。</p><p><img src="https://i.loli.net/2019/01/06/5c3196e0eb9e6.jpg" alt=""></p><p>sigmoid层输出0到1之间的数字，描述每个组件应该通过多少。 值为零意味着“不让任何东西通过”，而值为1则意味着“让一切都通过！”</p><p>LSTM具有三个这样的门，用于保护和控制单元状态。</p><h2 id="Step-by-Step-LSTM-Walk-Through"><a href="#Step-by-Step-LSTM-Walk-Through" class="headerlink" title="Step-by-Step LSTM Walk Through"></a>Step-by-Step LSTM Walk Through</h2><p>我们的第一步就是确定我们将从单元状态中丢弃的信息。这个决定是由一个称为“遗忘门层”的sigmoid层决定的。它查看$h_{t-1}$和$x_t$，并为单元状态$C_{t-1}$中的每一个数字输出一个介于0和1之间的数字。1代表“完全保留这个”，而0代表“完全舍弃这个”。</p><p>让我们回到我们的语言模型示例，试图根据以前的所有单词预测下一个单词。 在这样的问题中，单元状态可能包括当前受试者的性别，因此可以使用正确的代词。 当我们看到一个新主题时，我们想要忘记旧主题的性别。</p><p><img src="https://i.loli.net/2019/01/06/5c31997a2ecec.jpg" alt=""></p><p>下一步是确定我们将在单元状态中存储哪些新信息。 这有两个部分。 首先，称为“输入门层”的sigmoid层决定我们将更新哪些值。 接下来，tanh层创建可以添加到状态的新候选值$\tilde{C}_t$的向量。 在下一步中，我们将结合这两个来创建状态更新。</p><p>在我们的语言模型的例子中，我们想要将新主题的性别添加到单元格状态，以替换我们忘记的旧主题。</p><p><img src="https://i.loli.net/2019/01/06/5c319afb31868.jpg" alt=""></p><p>现在是时候将旧的单元状态$C_{T-1}$更新为新的单元状态$C_t$。 前面的步骤已经决定要做什么，我们只需要实际做到这一点。</p><p>我们将旧状态乘以$f_t$，忘记我们之前决定忘记的事情。 然后我们添加$i_t * \tilde{C}_t$。 这是新的候选值，根据我们决定更新每个状态的值来缩放。</p><p>在语言模型的情况下，我们实际上放弃了关于旧主题的性别的信息并添加新信息，正如我们在前面的步骤中所做的那样。</p><p><img src="https://i.loli.net/2019/01/06/5c319c9f37f63.jpg" alt=""></p><p>最后，我们需要决定我们要输出的内容。 此输出将基于我们的单元状态，但将是过滤版本。 首先，我们运行一个sigmoid层，它决定我们要输出的单元状态的哪些部分。 然后，我们将单元格状态设置为tanh（将值推到介于-1和1之间）并将其乘以sigmoid门的输出，以便我们只输出我们决定的部分。</p><p>对于语言模型示例，由于它只是看到一个主题，它可能想要输出与动词相关的信息，以防接下来会发生什么。 例如，它可能输出主语是单数还是复数，以便我们知道动词应该与什么形式共轭，如果接下来的话。</p><p><img src="https://i.loli.net/2019/01/06/5c319da831938.jpg" alt=""></p><h2 id="Variants-on-Long-Short-Term-Memory"><a href="#Variants-on-Long-Short-Term-Memory" class="headerlink" title="Variants on Long Short Term Memory"></a>Variants on Long Short Term Memory</h2><p>到目前为止我所描述的是一个非常正常的LSTM。 但并非所有LSTM都与上述相同。 事实上，似乎几乎所有涉及LSTM的论文都使用略有不同的版本。 差异很小，但值得一提的是其中一些。</p><blockquote><p>One popular LSTM variant, introduced by <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a>, is adding “peephole connections.” This means that we let the gate layers look at the cell state.</p></blockquote><p><img src="https://i.loli.net/2019/01/06/5c319ec053e96.jpg" alt=""></p><p>上面的图表为所有门增加了窥视孔（peephole），但是许多论文会给一些窥视孔而不是其他的。</p><p>另一种变化是使用耦合的遗忘和输入门。 我们不是单独决定忘记什么以及应该添加新信息，而是一起做出这些决定。<strong>我们仅仅会当我们在当前位置将要输入时忘记。我们仅仅输入新的值到那些我们已经忘记旧的信息的那些状态</strong> 。</p><p><img src="https://i.loli.net/2019/01/06/5c31a06e327f5.jpg" alt=""></p><p>另一个改动较大的变体是 Gated Recurrent Unit (GRU)，这是由 <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a> 提出。它将遗忘和输入门组合成一个“更新门”。它还合并了单元状态和隐藏状态，并进行了一些其他更改。 由此产生的模型比标准LSTM模型简单，并且越来越受欢迎。</p><p><img src="https://i.loli.net/2019/01/06/5c31a1285f207.jpg" alt=""></p><p>这些只是最着名的LSTM变种中的一小部分。 还有很多其他的东西，如 <a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a> 提出的 Depth Gated RNN。 还有一些完全不同的解决长期依赖关系的方法，如 <a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a> 提出的 Clockwork RNN。</p><p>哪种变体最好？ 差异是否重要？  <a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> 对流行变体进行了很好的比较，发现它们几乎完全相同。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> 测试了超过一万个RNN架构，找到了一些在某些任务上比LSTM更好的架构。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>早些时候，我提到了人们用RNN取得的显着成果。基本上所有这些都是使用LSTM实现的。对于大多数任务来说，它们确实工作得更好！</p><p>作为一组方程写下来，LSTM看起来非常令人生畏。希望，在这篇文章中逐步走过它们使他们更加平易近人。</p><p>LSTM是我们用RNN实现的重要一步。很自然地想知道：还有另一个重要的一步吗？研究人员的共同观点是：“是的！下一步是它的注意！“我们的想法是让RNN的每一步都从一些更大的信息集中选择信息。例如，如果您使用RNN创建描述图像的标题，则可能会选择图像的一部分来查看其输出的每个单词。</p><p>事实上， <a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="noopener">Xu, <em>et al.</em>(2015)</a> 做到这一点 - 如果你想探索注意力，这可能是一个有趣的起点！使用注意力已经取得了许多非常令人兴奋的结果，似乎还有更多的事情即将来临……</p><p>注意力不是RNN研究中唯一令人兴奋的问题。例如，<a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="noopener">Kalchbrenner, <em>et al.</em> (2015)</a> 的Grid LSTMs似乎非常有希望。在生成模型中使用RNN工作 - 例如<a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="noopener">Gregor, <em>et al.</em> (2015)</a>, <a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="noopener">Chung, <em>et al.</em> (2015)</a>, 或者 <a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="noopener">Bayer &amp; Osendorfer (2015)</a>  似乎也很有趣。过去几年对于反复出现的神经网络来说是一个激动人心的时刻，即将到来的那些承诺只会更加如此！</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt;。这篇文章很好很细的一步一步的分解讲解了LSTM，之前看过一篇翻译的博客，现在自己翻译一遍，感觉对LSTM的认识加深了许多，虽然还是对LSTM中存有一些问题，比如为什么用tanh，sigmoid，为什不采用其他的？，但是看过之后至少对LSTM没有那么畏惧，不觉得过于复杂了。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="神经网络" scheme="http://yoursite.com/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>《Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation》阅读笔记</title>
    <link href="http://yoursite.com/post/Learning_Phrase_Representations_using_RNN_Encoder%E2%80%93Decoder_for_Statistical_Machine_Translation/"/>
    <id>http://yoursite.com/post/Learning_Phrase_Representations_using_RNN_Encoder–Decoder_for_Statistical_Machine_Translation/</id>
    <published>2019-01-05T02:23:27.000Z</published>
    <updated>2019-01-06T06:45:24.506Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://www.aclweb.org/anthology/D14-1179" target="_blank" rel="noopener">原文链接</a>。该论文是Sequence to Sequence学习的最早原型，论文中提出一种崭新的RNN(GRU) Encoder-Decoder算法，虽然文章属于比较旧的文章，但作为seq2seq的基础原型，还是需要阅读了解一下的。文章写的比较详细，各部分细节都有讲解。</p></blockquote><a id="more"></a><h2 id="文章的主要结构"><a href="#文章的主要结构" class="headerlink" title="文章的主要结构"></a>文章的主要结构</h2><p><img src="https://i.loli.net/2019/01/05/5c3019fd55653.jpg" alt=""></p><h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><ul><li><p>a novel RNN Encoder–Decoder</p><p>能够处理变长序列</p></li><li><p>a novel hidden unit</p><ul><li>reset gate</li><li>update gate</li></ul></li></ul><h2 id="RNN-Encoder–Decoder"><a href="#RNN-Encoder–Decoder" class="headerlink" title="RNN Encoder–Decoder"></a>RNN Encoder–Decoder</h2><p>模型结构图如下：</p><p><img src="https://i.loli.net/2019/01/05/5c301b9717fd8.jpg" alt=""></p><p>文中作者对齐进行总体概述为：</p><blockquote><p>From a probabilistic perspective, this new model is a general method to learn the conditional distribution over a variable-length sequence conditioned on yet another variable-length sequence</p></blockquote><p>从概率的角度来看，这个新模型是学习在另一个可变长度序列条件下的可变长度序列上的条件分布的一般方法</p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>这部分是一个RNN单元。每个时间步，我们向Encoder中输入一个字/词（一般为向量形式），直到我们输入这个句子的最后一个字/词$X_T$，然后输入整个句子的语义向量c。由于RNN的特带你就是把前面每一步的输入信息都考虑进来，所以理论上这个c就包含了整个句子的所有信息。我们可以把当成这个句子的一个语义表示。</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder是另一个RNN，其被训练出来以通过预测隐藏状态$h_t$的下一个符号$y_t$来生成输出序列。计算公式如下</p><script type="math/tex; mode=display">h_t = f(h_{t-1},y_{t-1},c)</script><p>下一个序列的计算公式如下：</p><script type="math/tex; mode=display">P(y_t|y_{t-1},y_{t-2},\dots,y_1,c)=g(h_t,y_{t-1},c)</script><h2 id="Hidden-Unit"><a href="#Hidden-Unit" class="headerlink" title="Hidden Unit"></a>Hidden Unit</h2><p>该部分是对各部分具体的公式讲解，实际是GRU的具体公式算法，不再此详细叙述了。</p><h3 id="reset-gate"><a href="#reset-gate" class="headerlink" title="reset gate"></a>reset gate</h3><blockquote><p>In this formulation, when the reset gate is close to 0, the hidden state is forced to ignore the pre- vious hidden state and reset with the current input only. This effectively allows the hidden state to drop any information that is found to be irrelevant later in the future, thus, allowing a more compact representation.</p></blockquote><p>这段原文主要讲解了复位门的作用：有效地允许隐藏状态丢弃在将来稍后发现不相关的任何信息，从而允许更紧凑的表示。</p><p><strong>当捕获短期依赖时，复位门活跃</strong></p><h3 id="update-gate"><a href="#update-gate" class="headerlink" title="update gate"></a>update gate</h3><blockquote><p>the update gate controls how much information from the previous hidden state will carry over to the current hidden state.</p></blockquote><p>更新门控制来自先前隐藏状态的多少信息将转移到当前隐藏状态。</p><p><strong>当捕获长期依赖时，更新门活跃</strong></p><h2 id="Statistical-Machine-Translation-SMT"><a href="#Statistical-Machine-Translation-SMT" class="headerlink" title="Statistical Machine Translation(SMT)"></a>Statistical Machine Translation(SMT)</h2><p><img src="https://i.loli.net/2019/01/05/5c30217d42b8e.jpg" alt=""></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>这部分作者主要做了量化分析和性质分析，主要就是说他的模型怎么厉害。。。（没有具体的数值指标，翻译的还不是中英翻译，想看的话可以去看一下，就不贴实验结果了）。</p><h2 id="future"><a href="#future" class="headerlink" title="future"></a>future</h2><p>这里作者提出了可以用decoder生成的目标短语来替换原句中短语的思路，如果没记错的话，这个想法好像对后面的机器翻译有很大的指导作用。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/D14-1179&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt;。该论文是Sequence to Sequence学习的最早原型，论文中提出一种崭新的RNN(GRU) Encoder-Decoder算法，虽然文章属于比较旧的文章，但作为seq2seq的基础原型，还是需要阅读了解一下的。文章写的比较详细，各部分细节都有讲解。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
      <category term="seq2seq" scheme="http://yoursite.com/tags/seq2seq/"/>
    
  </entry>
  
</feed>
